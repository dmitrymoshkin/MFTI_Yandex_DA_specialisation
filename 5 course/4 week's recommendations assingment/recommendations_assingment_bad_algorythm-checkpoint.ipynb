{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data by-line:\n",
    "\n",
    "Импорт построчно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0,1,2,3,4,5', ''],\n",
       " ['9,10,11,9,11,12,9,11', ''],\n",
       " ['16,17,18,19,20,21', ''],\n",
       " ['24,25,26,27,24', '']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('coursera_sessions_train.txt') as file:\n",
    "    train_data = [i.replace('\\n', '').split(';') for i in file.readlines()]\n",
    "train_data[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating bag of words from train data:\n",
    "\n",
    "Cоздание мешка из просмотренных индексов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagow_views = []\n",
    "for i in train_data:\n",
    "    z = i[0].split(',')\n",
    "    for j in z:\n",
    "        bagow_views.append(j)\n",
    "bagow_purchases = []\n",
    "for i in train_data:\n",
    "    z = i[1].split(',')\n",
    "    for j in z:\n",
    "        bagow_purchases.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training massive - making each line a tuple of 2 lists: viewed items indices and purchased items indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prepared = [(i[0].split(','), i[1].split(',')) for i in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function sorts a single line in massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter(string, train_data):\n",
    "    import operator\n",
    "    \"\"\"Sort indeces of items watched by customer popularity-wise\n",
    "    \"\"\"\n",
    "    z = []\n",
    "    for i in string:\n",
    "        z.append((i, train_data.count(i)))\n",
    "    return [i[0] for i in sorted(z, key=operator.itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter_tester(string_sorter):\n",
    "    base = ['1'] + ['2'] * 2 + ['3'] * 3 + [\"4\"] * 4\n",
    "    string = (['1']+['2']+['3']+['4'], ['6']+['2']+['8'])\n",
    "    ans1 = ['4', '3', '2', '1']\n",
    "    if string_sorter(string[0], base) != ans1:\n",
    "        print('test 1 error')\n",
    "    ans2 = ['2', '6', '8']\n",
    "    if string_sorter(string[1], base) != ans2:\n",
    "        print('test 2 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_sorter_tester(string_sorter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sorted by-line massive where each line contains tuple representing one session and consisted of two lists: first with indices of watched items and latter with indices of items that have been bought.\n",
    "\n",
    "В итоге будем получать отсортированный массив, где каждая строка это тьюпл, представляющий одну сессию и включающий в свою очередь два листа: первый с индексами просмотренных товаров, второй с индексами купленных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function sorting whole massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massive_sorter(data, bag_of_words):\n",
    "    ''' Sorts indices in massive by-line according to bag of words frequencies. Massive must consist\n",
    "    of lines with a tuple each. Each tuple must contain two lists, both with items indeces.\n",
    "    '''\n",
    "    c = 0\n",
    "    sorted = []\n",
    "    for i in data:\n",
    "        if len(i[1]) > 1:\n",
    "            sorted.append((string_sorter(i[0], bag_of_words), string_sorter(i[1], bag_of_words)))\n",
    "        else:\n",
    "               sorted.append((string_sorter(i[0], bag_of_words), ''))\n",
    "        c += 1\n",
    "        print(c)\n",
    "    return sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prepared_sorted = massive_sorter(train_data_prepared, bagow_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '10', ..., '99996', '99997', '99998'], dtype='<U6'),\n",
       " array([6, 6, 7, ..., 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = np.unique(bagow_views, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictfreq = {}\n",
    "for i, j in zip(counts[0], counts[1]):\n",
    "    dictfreq[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter_dict(string, train_data):\n",
    "    import operator\n",
    "    \"\"\"Sort indeces of items watched by customer popularity-wise\n",
    "    \"\"\"\n",
    "    z = []\n",
    "    for i in string:\n",
    "        z.append((i, dictfreq[i]))\n",
    "    return [i[0] for i in sorted(z, key=operator.itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1, 100):\n",
    "    string_sorter_dict(train_data_prepared[i][0], bagow_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1, 100):\n",
    "    z = string_sorter(train_data_prepared[i][0], bagow_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
