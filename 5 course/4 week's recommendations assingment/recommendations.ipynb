{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation system for shop web-site.\n",
    "Processing data with unique sessions where users' interacted with shop's web-site. For each session viewed items' indices and bought items' indices are given.\n",
    "Goals:\n",
    "- Build recommendation system based on a) viewing popluraty of items b) a) purchasing popluraty of items. \n",
    "- Amount of recommended items for user is equal or less than amount of viewed items. \n",
    "- Show unique items.\n",
    "- Evaluate quality by using AP@k and AR@k for k=1 and k=5 where amount of recommended items does not exceed k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline:\n",
    "    1. Define import functions\n",
    "    2. Define function that creates dicts for sorting\n",
    "    3. Define fuction that transforms and sorts sample with dict\n",
    "    4. Define metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_train_data():\n",
    "    '''\n",
    "    Imports train data by-line\n",
    "    '''\n",
    "    with open('sessions_train.txt') as file:\n",
    "        return [i.replace('\\n', '').split(';') for i in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_test_data():\n",
    "    '''\n",
    "    Imports test data by-line\n",
    "    '''\n",
    "    with open('sessions_test.txt') as file:\n",
    "        return [i.replace('\\n', '').split(';') for i in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that creates two dicts by which samples will be sorted. \n",
    "\n",
    "First where keys are viewed items' unique indeces in train sample and values are corresponding quantities. \n",
    "\n",
    "Second where keys are bought items' unique indeces in train sample and values are corresponding quantities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicts_creator():\n",
    "\n",
    "# load train data\n",
    "    train_data = import_train_data()\n",
    "    \n",
    "# create bag of words from all viewed items\n",
    "\n",
    "    bagow_views = []\n",
    "    for i in train_data:\n",
    "        z = i[0].split(',')\n",
    "        for j in z:\n",
    "            bagow_views.append(j)\n",
    "\n",
    "# create bag of words from all bought items (empty sessions excluded)\n",
    "       \n",
    "    bagow_purchases = []\n",
    "    for i in train_data:\n",
    "        if len(i[1]) > 0:\n",
    "            z = i[1].split(',')\n",
    "        for j in z:\n",
    "            bagow_purchases.append(j)\n",
    "\n",
    "# create dict of {'unique viewed item index': quantity of views} kind\n",
    "\n",
    "    counts_views = np.unique(bag_of_words()[0], return_counts=True)\n",
    "    dictfreq_views = {}\n",
    "    for i, j in zip(counts_views[0], counts_views[1]):\n",
    "        dictfreq_views[i] = j\n",
    "    \n",
    "# create dict of {'unique purchased item index': quantity of purchases} kind\n",
    "    \n",
    "    counts_purchases = np.unique(bag_of_words()[1], return_counts=True)\n",
    "    dictfreq_purchases = {}\n",
    "    for i, j in zip(counts_purchases[0], counts_purchases[1]):\n",
    "        dictfreq_purchases[i] = j\n",
    "    return dictfreq_views, dictfreq_purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that sorts a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter(string, dict):\n",
    "    import operator\n",
    "    \"\"\"\n",
    "    Sorts indeces of items in one session\n",
    "    \"\"\"\n",
    "    z = []\n",
    "    for i in string:\n",
    "        try:\n",
    "            z.append((i, dict[i]))\n",
    "        except KeyError:\n",
    "            z.append((i, 0))\n",
    "    return [i[0] for i in sorted(z, key=operator.itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter_tester(string_sorter):\n",
    "    base = {'1':1, '2':2, '3':3, '4':4}\n",
    "    string = (['1']+['2']+['3']+['4'], ['6']+['2']+['8'])\n",
    "    ans1 = ['4', '3', '2', '1']\n",
    "    if string_sorter(string[0], base) != ans1:\n",
    "        print('test 1 error')\n",
    "    ans2 = ['2', '6', '8']\n",
    "    if string_sorter(string[1], base) != ans2:\n",
    "        print('test 2 error')\n",
    "    base = {'1':1, '2':2, '3':2, '4':4}\n",
    "    string = (['1']+['3']+['2']+['4']+['6']+['5'], ['6']+['2']+['8'])\n",
    "    ans3 = ['4', '3', '2', '1', '6', '5']\n",
    "    if string_sorter(string[0], base) != ans3:\n",
    "        print('test 3 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_sorter_tester(string_sorter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that sorts whole massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massive_sorter(data, dict):\n",
    "    ''' Sorts viewed indices in massive by-line according to theirs frequencies. Massive must consist\n",
    "    of lines with a tuple each. Each tuple must contain two lists, both with items indices.\n",
    "    '''\n",
    "    \n",
    "    # Make each line in massive a tuple of 2 lists: unique viewed items indices \n",
    "    # and purchased items indices respectively. \n",
    "    \n",
    "    data_prepared = [(np.unique(i[0].split(',')), i[1].split(',')) \n",
    "                       for i in data if len(i[1])>0]\n",
    "    \n",
    "    # Sort massive by-line\n",
    "    \n",
    "    sorted = []\n",
    "    for i in data_prepared:\n",
    "        sorted.append((string_sorter(i[0], dict), i[1]))\n",
    "    return sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics. Average precision and average recall are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions that count presicion, recall for one session and average precision, recall for whole massive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def precision_line(line, km):\n",
    "    '''Counts presicion for a line\n",
    "    '''\n",
    "    l = [1 if i in line[1] else 0 for i in line[0]]\n",
    "    return sum(l[0:km])/km\n",
    "def precision(massive, km):\n",
    "    '''Counts average presicion for a massive\n",
    "    '''\n",
    "    l = []\n",
    "    for line in massive:\n",
    "        l.append(precision_line(line, km))\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_line(line, km):\n",
    "    '''Counts recall for a line\n",
    "    '''\n",
    "    l = [1 if i in line[1] else 0 for i in line[0]]\n",
    "    return sum(l[0:km])/len(line[1])\n",
    "def recall(massive, km):\n",
    "    '''Counts average recall for a massive\n",
    "    '''\n",
    "    l = []\n",
    "    for line in massive:\n",
    "        l.append(recall_line(line, km))\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalltest(recall):\n",
    "    x1 = [([1, 2, 3], [0, 2]), ([4, 5, 6], [1])]\n",
    "    if recall(x1, 3) != 0.25:\n",
    "        print('test1 error')\n",
    "        return recall(x1, 3)\n",
    "    x2 = [([1, 2, 3], [0, 2]), ([4, 5], [1, 2, 3])]\n",
    "    if recall(x2, 3) != 0.25:\n",
    "        print('test2 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalltest(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metrics on train sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted_views = massive_sorter(import_train_data(), dicts_creator()[0])\n",
    "train_sorted_purchases = massive_sorter(import_train_data(), dicts_creator()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most viewed items on train sample k=1: 0.438292114082025\n",
      "presicion on most viewed items on train sample k=1: 0.5069290465631929\n",
      "recall on most viewed items on train sample k=5: 0.8238064465406484\n",
      "presicion on most viewed items on train sample k=5: 0.21213968957872026\n"
     ]
    }
   ],
   "source": [
    "# train sample. Recommendations by views rating\n",
    "k = 1\n",
    "r1 = recall(train_sorted_views, k)\n",
    "print('recall on most viewed items on train sample k=1:', r1)\n",
    "p1 = precision(train_sorted_views, k)\n",
    "print('presicion on most viewed items on train sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(train_sorted_views, k)\n",
    "print('recall on most viewed items on train sample k=5:', r5)\n",
    "p5 = precision(train_sorted_views, k)\n",
    "print('presicion on most viewed items on train sample k=5:', p5)\n",
    "with open('quality_views_train.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most purchased items on train sample k=1: 0.6666722789713365\n",
      "presicion on most purchased items on train sample k=1: 0.7732815964523282\n",
      "recall on most purchased items on train sample k=5: 0.9253956378679217\n",
      "presicion on most purchased items on train sample k=5: 0.25232815964524263\n"
     ]
    }
   ],
   "source": [
    "# train sample. Recommendations by purchasing rating\n",
    "k = 1\n",
    "r1 = recall(train_sorted_purchases, k)\n",
    "print('recall on most purchased items on train sample k=1:', r1)\n",
    "p1 = precision(train_sorted_purchases, k)\n",
    "print('presicion on most purchased items on train sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(train_sorted_purchases, k)\n",
    "print('recall on most purchased items on train sample k=5:', r5)\n",
    "p5 = precision(train_sorted_purchases, k)\n",
    "print('presicion on most purchased items on train sample k=5:', p5)\n",
    "with open('quality_purchases_train.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metrics on test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted_views = massive_sorter(import_test_data(), dicts_creator()[0])\n",
    "test_sorted_purchases = massive_sorter(import_test_data(), dicts_creator()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most viewed items on test sample k=1: 0.41399478117759125\n",
      "presicion on most viewed items on test sample k=1: 0.47748976807639837\n",
      "recall on most viewed items on test sample k=5: 0.7990271151422681\n",
      "presicion on most viewed items on test sample k=5: 0.20381991814461664\n"
     ]
    }
   ],
   "source": [
    "# test sample. Recommendations by views rating\n",
    "k = 1\n",
    "r1 = recall(test_sorted_views, k)\n",
    "print('recall on most viewed items on test sample k=1:', r1)\n",
    "p1 = precision(test_sorted_views, k)\n",
    "print('presicion on most viewed items on test sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(test_sorted_views, k)\n",
    "print('recall on most viewed items on test sample k=5:', r5)\n",
    "p5 = precision(test_sorted_views, k)\n",
    "print('presicion on most viewed items on test sample k=5:', p5)\n",
    "with open('quality_views_test.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most purchased items on test sample k=1: 0.4229841486389914\n",
      "presicion on most purchased items on test sample k=1: 0.48894952251023194\n",
      "recall on most purchased items on test sample k=5: 0.7964858594403513\n",
      "presicion on most purchased items on test sample k=5: 0.20414733969986873\n"
     ]
    }
   ],
   "source": [
    "# test sample. Recommendations by purchasing rating\n",
    "k = 1\n",
    "r1 = recall(test_sorted_purchases, k)\n",
    "print('recall on most purchased items on test sample k=1:', r1)\n",
    "p1 = precision(test_sorted_purchases, k)\n",
    "print('presicion on most purchased items on test sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(test_sorted_purchases, k)\n",
    "print('recall on most purchased items on test sample k=5:', r5)\n",
    "p5 = precision(test_sorted_purchases, k)\n",
    "print('presicion on most purchased items on test sample k=5:', p5)\n",
    "with open('quality_purchases_test.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
