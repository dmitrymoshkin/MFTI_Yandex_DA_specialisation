{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data by-line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0,1,2,3,4,5', ''],\n",
       " ['9,10,11,9,11,12,9,11', ''],\n",
       " ['16,17,18,19,20,21', ''],\n",
       " ['24,25,26,27,24', '']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('coursera_sessions_train.txt') as file:\n",
    "    train_data = [i.replace('\\n', '').split(';') for i in file.readlines()]\n",
    "train_data[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating bag of words from train data.\n",
    "\n",
    "Count unique indeces and create a dictionary [item]=frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagow_views = []\n",
    "for i in train_data:\n",
    "    z = i[0].split(',')\n",
    "    for j in z:\n",
    "        bagow_views.append(j)\n",
    "bagow_purchases = []\n",
    "for i in train_data:\n",
    "    z = i[1].split(',')\n",
    "    for j in z:\n",
    "        bagow_purchases.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_views = np.unique(bagow_views, return_counts=True)\n",
    "dictfreq_views = {}\n",
    "for i, j in zip(counts_views[0], counts_views[1]):\n",
    "    dictfreq_views[i] = j\n",
    "counts_purchases = np.unique(bagow_purchases, return_counts=True)\n",
    "dictfreq_purchases = {}\n",
    "for i, j in zip(counts_purchases[0], counts_purchases[1]):\n",
    "    dictfreq_purchases[i] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function sorts a single line in massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter(string, dict):\n",
    "    import operator\n",
    "    \"\"\"Sort indeces of items watched by customer popularity-wise\n",
    "    \"\"\"\n",
    "    z = []\n",
    "    for i in string:\n",
    "        try:\n",
    "            z.append((i, dict[i]))\n",
    "        except KeyError:\n",
    "            z.append((i, 0))\n",
    "    return [i[0] for i in sorted(z, key=operator.itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter_tester(string_sorter):\n",
    "    base = {'1':1, '2':2, '3':3, '4':4}\n",
    "    string = (['1']+['2']+['3']+['4'], ['6']+['2']+['8'])\n",
    "    ans1 = ['4', '3', '2', '1']\n",
    "    if string_sorter(string[0], base) != ans1:\n",
    "        print('test 1 error')\n",
    "    ans2 = ['2', '6', '8']\n",
    "    if string_sorter(string[1], base) != ans2:\n",
    "        print('test 2 error')\n",
    "    base = {'1':1, '2':2, '3':2, '4':4}\n",
    "    string = (['1']+['3']+['2']+['4']+['6']+['5'], ['6']+['2']+['8'])\n",
    "    ans3 = ['4', '3', '2', '1', '6', '5']\n",
    "    if string_sorter(string[0], base) != ans3:\n",
    "        print('test 3 error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sorted by-line massive where each line contains tuple representing one session and consisted of two lists: first with indices of watched items and latter with indices of items that have been bought.\n",
    "\n",
    "В итоге будем получать отсортированный массив, где каждая строка это тьюпл, представляющий одну сессию и включающий в свою очередь два листа: первый с индексами просмотренных товаров, второй с индексами купленных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function sorting whole massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massive_sorter(data, dict):\n",
    "    ''' Sorts indices in massive by-line according to theirs frequencies. Massive must consist\n",
    "    of lines with a tuple each. Each tuple must contain two lists, both with items indices.\n",
    "    '''\n",
    "    sorted = []\n",
    "    for i in data:\n",
    "        if len(i[1]) > 1:\n",
    "            sorted.append((string_sorter(i[0], dict), string_sorter(i[1], dict)))\n",
    "        else:\n",
    "               sorted.append((string_sorter(i[0], dict), ''))\n",
    "    return sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process train data. Making each line in massive a tuple of 2 lists: viewed items indices and purchased items indices. Then soring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prepared = [(set(i[0].split(',')), i[1].split(',')) for i in train_data if len(i[1])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted_views = massive_sorter(train_data_prepared, dictfreq_views)\n",
    "train_sorted_purchases = massive_sorter(train_data_prepared, dictfreq_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete sessions without purchases.\n",
    "train_sorted_views_with_purchases = [i for i in train_sorted_views if len(i[1]) > 0]\n",
    "train_sorted_purchases_with_purchases = [i for i in train_sorted_purchases if len(i[1]) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and process test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6,7,8', ''], ['13,14,15', ''], ['22,23', ''], ['28,29,30,31,32,33', '']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('coursera_sessions_test.txt') as file:\n",
    "    test_data = [i.replace('\\n', '').split(';') for i in file.readlines()]\n",
    "test_data[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prepared = [(set(i[0].split(',')), i[1].split(',')) for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted_views = massive_sorter(test_data_prepared, dictfreq_views)\n",
    "test_sorted_purchases = massive_sorter(test_data_prepared, dictfreq_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete sessions without purchases.\n",
    "test_sorted_views_with_purchases = [i for i in test_sorted_views if len(i[1]) > 0]\n",
    "test_sorted_purchases_with_purchases = [i for i in test_sorted_purchases if len(i[1]) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics. Average precision and average recall are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function counts presicion for one session and average precision for whole massive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def presicionatk(line, km):\n",
    "    '''Count presicion for a line\n",
    "    '''\n",
    "    l = [1 if i in line[1] else 0 for i in line[0]]\n",
    "    return sum(l[0:km])/km\n",
    "def presicion(massive, km):\n",
    "    '''Count average presicion for a massive\n",
    "    '''\n",
    "    l = []\n",
    "    for line in massive:\n",
    "        l.append(presicionatk(line, km))\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presicion of recomendations on most purchased items on train sample: 0.7467672413793104\n",
      "presicion of recomendations on most viewed items on test sample: 0.42780172413793105\n",
      "presicion of recomendations on most purchased items on test sample: 0.4385775862068966\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "\n",
    "p2 = presicion(train_sorted_purchases_with_purchases, k)\n",
    "print('presicion of recomendations on most purchased items on train sample:', p2)\n",
    "p3 = presicion(test_sorted_views_with_purchases, k)\n",
    "print('presicion of recomendations on most viewed items on test sample:', p3)\n",
    "p4 = presicion(test_sorted_purchases_with_purchases, k)\n",
    "print('presicion of recomendations on most purchased items on test sample:', p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presicion of recomendations on most viewed items on train sample: 0.7489224137931034\n",
      "presicion of recomendations on most purchased items on train sample: 0.7467672413793104\n",
      "presicion of recomendations on most viewed items on test sample: 0.42780172413793105\n",
      "presicion of recomendations on most purchased items on test sample: 0.4385775862068966\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "p5 = presicion(train_sorted_views_with_purchases, k)\n",
    "print('presicion of recomendations on most viewed items on train sample:', p1)\n",
    "p6 = presicion(train_sorted_purchases_with_purchases, k)\n",
    "print('presicion of recomendations on most purchased items on train sample:', p2)\n",
    "p7 = presicion(test_sorted_views_with_purchases, k)\n",
    "print('presicion of recomendations on most viewed items on test sample:', p3)\n",
    "p8 = presicion(test_sorted_purchases_with_purchases, k)\n",
    "print('presicion of recomendations on most purchased items on test sample:', p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallatk(line, km):\n",
    "    '''Count presicion for a line\n",
    "    '''\n",
    "    l = [1 if i in line[1] else 0 for i in line[0]]\n",
    "    return sum(l[0:km])/len(line[1])\n",
    "def recall(massive, km):\n",
    "    '''Count average presicion for a massive\n",
    "    '''\n",
    "    l = []\n",
    "    for line in massive:\n",
    "        l.append(recallatk(line, km))\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalltest(recall):\n",
    "    x1 = [([1, 2, 3], [0, 2]), ([4, 5, 6], [1])]\n",
    "    if recall(x1, 3) != 0.25:\n",
    "        print('test1 error')\n",
    "        return recall(x1, 3)\n",
    "    x2 = [([1, 2, 3], [0, 2]), ([4, 5], [1, 2, 3])]\n",
    "    if recall(x2, 3) != 0.25:\n",
    "        print('test2 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalltest(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most viewed items on train sample k=1: 0.18165367917523093\n",
      "presicion on most viewed items on train sample k=1: 0.44935344827586204\n",
      "recall on most viewed items on train sample k=5: 0.5918377210672469\n",
      "presicion on most viewed items on train sample k=5: 0.30323275862068866\n"
     ]
    }
   ],
   "source": [
    "# train sample. Recommendations by views rating\n",
    "k = 1\n",
    "r1 = recall(train_sorted_views_with_purchases, k)\n",
    "print('recall on most viewed items on train sample k=1:', r1)\n",
    "p1 = presicion(train_sorted_views_with_purchases, k)\n",
    "print('presicion on most viewed items on train sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(train_sorted_views_with_purchases, k)\n",
    "print('recall on most viewed items on train sample k=5:', r5)\n",
    "p5 = presicion(train_sorted_views_with_purchases, k)\n",
    "print('presicion on most viewed items on train sample k=5:', p5)\n",
    "with open('quality_views_train.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most purchased items on train sample k=1: 0.2991836587741761\n",
      "presicion on most purchased items on train sample k=1: 0.7467672413793104\n",
      "recall on most purchased items on train sample k=5: 0.7792672425754316\n",
      "presicion on most purchased items on train sample k=5: 0.4165948275862045\n"
     ]
    }
   ],
   "source": [
    "# train sample. Recommendations by purchasing rating\n",
    "k = 1\n",
    "r1 = recall(train_sorted_purchases_with_purchases, k)\n",
    "print('recall on most purchased items on train sample k=1:', r1)\n",
    "p1 = presicion(train_sorted_purchases_with_purchases, k)\n",
    "print('presicion on most purchased items on train sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(train_sorted_purchases_with_purchases, k)\n",
    "print('recall on most purchased items on train sample k=5:', r5)\n",
    "p5 = presicion(train_sorted_purchases_with_purchases, k)\n",
    "print('presicion on most purchased items on train sample k=5:', p5)\n",
    "with open('quality_purchases_train.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most viewed items on test sample k=1: 0.1756982929666119\n",
      "presicion on most viewed items on test sample k=1: 0.42780172413793105\n",
      "recall on most viewed items on test sample k=5: 0.5619503583534137\n",
      "presicion on most viewed items on test sample k=5: 0.2855603448275858\n"
     ]
    }
   ],
   "source": [
    "# test sample. Recommendations by views rating\n",
    "k = 1\n",
    "r1 = recall(test_sorted_views_with_purchases, k)\n",
    "print('recall on most viewed items on test sample k=1:', r1)\n",
    "p1 = presicion(test_sorted_views_with_purchases, k)\n",
    "print('presicion on most viewed items on test sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(test_sorted_views_with_purchases, k)\n",
    "print('recall on most viewed items on test sample k=5:', r5)\n",
    "p5 = presicion(test_sorted_views_with_purchases, k)\n",
    "print('presicion on most viewed items on test sample k=5:', p5)\n",
    "with open('quality_views_test.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall on most purchased items on test sample k=1: 0.1815880285303777\n",
      "presicion on most purchased items on test sample k=1: 0.4385775862068966\n",
      "recall on most purchased items on test sample k=5: 0.5538708010994777\n",
      "presicion on most purchased items on test sample k=5: 0.28232758620689624\n"
     ]
    }
   ],
   "source": [
    "# test sample. Recommendations by purchasing rating\n",
    "k = 1\n",
    "r1 = recall(test_sorted_purchases_with_purchases, k)\n",
    "print('recall on most purchased items on test sample k=1:', r1)\n",
    "p1 = presicion(test_sorted_purchases_with_purchases, k)\n",
    "print('presicion on most purchased items on test sample k=1:', p1)\n",
    "k = 5\n",
    "r5 = recall(test_sorted_purchases_with_purchases, k)\n",
    "print('recall on most purchased items on test sample k=5:', r5)\n",
    "p5 = presicion(test_sorted_purchases_with_purchases, k)\n",
    "print('presicion on most purchased items on test sample k=5:', p5)\n",
    "with open('quality_purchases_test.txt', 'w') as f:\n",
    "    f.write((' ').join(list(map(lambda x: str(round(x, 2)), [r1, p1, r5, p5]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
