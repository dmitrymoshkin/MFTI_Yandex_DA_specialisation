{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data by-line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0,1,2,3,4,5', ''],\n",
       " ['9,10,11,9,11,12,9,11', ''],\n",
       " ['16,17,18,19,20,21', ''],\n",
       " ['24,25,26,27,24', '']]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('coursera_sessions_train.txt') as file:\n",
    "    train_data = [i.replace('\\n', '').split(';') for i in file.readlines()]\n",
    "train_data[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating bag of words from train data: 'bagow_views' - viewed items indices, 'bagow_purchases' - bought items indices (the latter are unique in each session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagow_views = []\n",
    "for i in train_data:\n",
    "    z = i[0].split(',')\n",
    "    for j in z:\n",
    "        bagow_views.append(j)\n",
    "bagow_purchases = []\n",
    "for i in train_data:\n",
    "    z = i[1].split(',')\n",
    "    for j in z:\n",
    "        bagow_purchases.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count unique indeces and create a dictionary 'item' : frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_views = np.unique(bagow_views, return_counts=True)\n",
    "dictfreq_views = {}\n",
    "for i, j in zip(counts_views[0], counts_views[1]):\n",
    "    dictfreq_views[i] = j\n",
    "counts_purchases = np.unique(bagow_purchases, return_counts=True)\n",
    "dictfreq_purchases = {}\n",
    "for i, j in zip(counts_purchases[0], counts_purchases[1]):\n",
    "    dictfreq_purchases[i] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function sorts a single line in massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter(string, dict):\n",
    "    import operator\n",
    "    \"\"\"Sorts indices of items watched by customer popularity-wise\n",
    "    \"\"\"\n",
    "    z = []\n",
    "    for i in string:\n",
    "        try:\n",
    "            z.append((i, dict[i]))\n",
    "        except KeyError:\n",
    "            z.append((i, 0))\n",
    "    return [i[0] for i in sorted(z, key=operator.itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sorter_tester(string_sorter):\n",
    "    base = {'1':1, '2':2, '3':3, '4':4}\n",
    "    string = (['1']+['2']+['3']+['4'], ['6']+['2']+['8'])\n",
    "    ans1 = ['4', '3', '2', '1']\n",
    "    if string_sorter(string[0], base) != ans1:\n",
    "        print('test 1 error')\n",
    "    ans2 = ['2', '6', '8']\n",
    "    if string_sorter(string[1], base) != ans2:\n",
    "        print('test 2 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_sorter_tester(string_sorter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sorted by-line massive where each line contains tuple representing one session and consisted of two lists: first with indices of watched items and latter with indices of items that have been bought.\n",
    "\n",
    "В итоге будем получать отсортированный массив, где каждая строка это тьюпл, представляющий одну сессию и включающий в свою очередь два листа: первый с индексами просмотренных товаров, второй с индексами купленных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function sorting whole massive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massive_sorter(data, dict):\n",
    "    ''' Sorts indices in massive by-line according to theirs frequencies. Massive must consist\n",
    "    of lines with a tuple each. Each tuple must contain two lists, both with items indices.\n",
    "    '''\n",
    "    sorted = []\n",
    "    for i in data:\n",
    "        if len(i[1]) > 1:\n",
    "            sorted.append((string_sorter(i[0], dict), string_sorter(i[1], dict)))\n",
    "        else:\n",
    "               sorted.append((string_sorter(i[0], dict), ''))\n",
    "    return sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process train data. Making each line in massive a tuple of 2 lists: viewed items indices and purchased items indices. Then soring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prepared = [(i[0].split(','), i[1].split(',')) for i in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted_views = massive_sorter(train_data_prepared, dictfreq_views)\n",
    "train_sorted_purchases = massive_sorter(train_data_prepared, dictfreq_purchases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and process test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6,7,8', ''], ['13,14,15', ''], ['22,23', ''], ['28,29,30,31,32,33', '']]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('coursera_sessions_test.txt') as file:\n",
    "    test_data = [i.replace('\\n', '').split(';') for i in file.readlines()]\n",
    "test_data[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prepared = [(set(i[0].split(',')), i[1].split(',')) for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted_views = massive_sorter(test_data_prepared, dictfreq_views)\n",
    "test_sorted_purchases = massive_sorter(test_data_prepared, dictfreq_purchases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics. Average precision and average recall are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete sessions without purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sorted_views_with_purchases = [i for i in train_sorted_views if len(i[1]) > 0]\n",
    "train_sorted_purchases_with_purchases = [i for i in train_sorted_purchases if len(i[1]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted_views_with_purchases = [i for i in test_sorted_views if len(i[1]) > 0]\n",
    "test_sorted_purchases_with_purchases = [i for i in test_sorted_purchases if len(i[1]) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function counts presicion for one session and average precision for whole massive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def presicionatk(line, km):\n",
    "    '''Count presicion for a line\n",
    "    '''\n",
    "    l = [1 if i in line[1] else 0 for i in line[0]]\n",
    "    p = 0\n",
    "    k = 1\n",
    "    for i in l[0:km]:\n",
    "        p = p + i/k\n",
    "        k += 1\n",
    "    return p\n",
    "def presicion(massive, km):\n",
    "    '''Count average presicion for a massive\n",
    "    '''\n",
    "    l = []\n",
    "    for line in massive:\n",
    "        l.append(precisionatk(line, km))\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallatk(line, km):\n",
    "    '''Count presicion for a line\n",
    "    '''\n",
    "    l = [1 if i in line[1] else 0 for i in line[0]]\n",
    "    p = 0\n",
    "    b = 1\n",
    "    for i in l[0:km]:\n",
    "        p = p + i/b\n",
    "        b = b+1 if b<len(line[1]) else b\n",
    "    return p\n",
    "def recall(massive, km):\n",
    "    '''Count average presicion for a massive\n",
    "    '''\n",
    "    l = []\n",
    "    for line in massive:\n",
    "        l.append(presicionatk(line, km))\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalltest(recall):\n",
    "    x1 = [([1, 2, 3], [0, 2]), ([4, 5, 6], [1])]\n",
    "    if recall(x1, 3) != 0.25:\n",
    "        print('test1 error')\n",
    "    x2 = [([1, 2, 3], [0, 2]), ([4, 5], [1, 2, 3])]\n",
    "    if recall(x2, 3) != 0.25:\n",
    "        print('test2 error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalltest(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of recomendations on most viewed items on train sample: 0.4536637931034483\n",
      "recall of recomendations on most purchased items on train sample: 0.7489224137931034\n",
      "recall of recomendations on most viewed items on test sample: 0.4234913793103448\n",
      "recall of recomendations on most purchased items on test sample: 0.4234913793103448\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "r1 = recall(train_sorted_views_with_purchases, k)\n",
    "print('recall of recomendations on most viewed items on train sample:', r1)\n",
    "r2 = recall(train_sorted_purchases_with_purchases, k)\n",
    "print('recall of recomendations on most purchased items on train sample:', r2)\n",
    "r3 = recall(test_sorted_views_with_purchases, k)\n",
    "print('recall of recomendations on most viewed items on test sample:', r3)\n",
    "r4 = recall(test_sorted_purchases_with_purchases, k)\n",
    "print('recall of recomendations on most purchased items on test sample:', r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of recomendations on most viewed items on train sample: 1.0010416666666713\n",
      "recall of recomendations on most purchased items on train sample: 1.5355244252873494\n",
      "recall of recomendations on most viewed items on test sample: 0.7799389367816115\n",
      "recall of recomendations on most purchased items on test sample: 0.7785380747126458\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "r5 = recall(train_sorted_views_with_purchases, k)\n",
    "print('recall of recomendations on most viewed items on train sample:', r5)\n",
    "r6 = recall(train_sorted_purchases_with_purchases, k)\n",
    "print('recall of recomendations on most purchased items on train sample:', r6)\n",
    "r7 = recall(test_sorted_views_with_purchases, k)\n",
    "print('recall of recomendations on most viewed items on test sample:', r7)\n",
    "r8 = recall(test_sorted_purchases_with_purchases, k)\n",
    "print('recall of recomendations on most purchased items on test sample:', r8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0 1.54 0.78 0.78'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(' ').join(list(map(lambda x: str(round(x, 2)), [p1, p2, p3, p4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer1.txt', 'w') as f:\n",
    "    f.write()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
