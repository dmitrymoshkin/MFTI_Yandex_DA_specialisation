{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;\n",
    "\n",
    "## <center>Отчет по проекту</center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### <center>«Идентификация интернет пользователей» </center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Мошкин Дмитрий </center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>2019</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "&nbsp;\n",
    "1. [Цель и задачи проекта. Описание исходных и обработанных данных и признаков](#1part)\n",
    "2. [Описание данных и их подготовка](#2part)\n",
    " - [Описание данных](#2.1part)\n",
    "  - [Создание сессий](#2.2part)\n",
    "  - [Применение мешка слов](#2.3part)\n",
    "  - [Варьирование длины сессии и скользящее окно](#2.4part)\n",
    "3. [Первичный анализ данных. Проверка гипотез](#3part)\n",
    "4. [Разработка признаков и их визуальный анализ](#4part);\n",
    "  - [Временные признаки и количество уникальных сайтов](#4.1part)\n",
    "  - [Вывод для каждого пользователя по построенным признакам](#4.2part)\n",
    "  - [Признаки \"работает или развлекается пользователь\"](#4.3part)\n",
    "5. [Сравнение алгоритмов и подбор модели](#5part);\n",
    "  - [Cравнение нескольких алгоритмов на сессиях из 10 сайтов](#5.1part)\n",
    "  - [Выбор параметров – длины сессии и ширины окна](#5.2part)\n",
    "  - [Идентификация конкретного пользователя и кривая обучения](#5.3part)\n",
    "6. [Соревнование Kaggle](#6part)\n",
    "  - [Анализ и подготовка данных](#6.1part)\n",
    "  - [Первый сабмит](#6.2part)\n",
    "  - [Второй сабмит](#6.3part)\n",
    "  - [Третий сабмит](#6.4part)\n",
    "7. [Работа с Worpal Wabbit](#7part)\n",
    "  - [Сравнение VW с SGD и LogReg](#7.1part)\n",
    "  - [Валидация по тестовой выборке (Public Leaderboard)](#7.2part)\n",
    "8. [Итоги, выводы и прогноз дальнейшей работы](#8part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1part'></a>\n",
    "### 1. Цель и задачи проекта. Описание исходных и обработанных данных и признаков\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Цель проекта.\n",
    "\n",
    "&#8195;Проект направлен на решение задачи идентификации пользователя по его поведению в сети Интернет. Задача как таковая является широкой в смысле выбора используемых признаков и стратегии. К примеру идентифицировать пользователя можно как по тому какие сайты в какое время он посещает, так и по тому как он это делает - какими разделами сайта он пользуется, как быстро отвечает на сообщения в социальных сетях, насколько длинны оставляемые им комментарии, или он предпочитает их не оставлять и т.д.\n",
    "\n",
    "&#8195;Целью данного проекта является построение алгоритма идентификации пользователя по имеющимся данным с последовательностями посещенных пользователями сайтов и времени посещения каждого из них.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Задачи проекта.\n",
    "\n",
    "- Предобработка данных, подготовка их к классификации\n",
    "- Первичный и визуальный анализ\n",
    "- Разработка признаков и их описание\n",
    "- Сравнение семейств моделей классификации и подбор параметров выбранной модели\n",
    "- Оценка метрик и вывод по проделанной работе\n",
    "- Прогноз по дальнейшей работе\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2part'></a>\n",
    "### 2. Описание данных и их подготовка\n",
    "&nbsp;\n",
    "\n",
    "<a id='2.1part'></a>\n",
    "#### Описание данных\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Имеются данные с прокси-серверов Университета Блеза Паскаля.\n",
    "\n",
    "&#8195;Для каждого пользователя заведен csv-файл с названием user****.csv (где вместо звездочек – 4 цифры, соответствующие ID пользователя), а в нем посещения сайтов записаны в следующем формате: \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>*timestamp, посещенный веб-сайт*</center>\n",
    "&nbsp;\n",
    "\n",
    "&#8195;В дальнейшем будет использоваться параллельно 2 выборки: по 10 и по 150  пользователям. Для 10 пользователей будет отлаживаться код, для 150 будет использоваться рабочая версия.\n",
    "\n",
    "&#8195;Вид исходных данных приведен ниже. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-yw4l\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">2013-11-15 08:12:07</td>\n",
    "    <td class=\"tg-yw4l\">fpdownload2.macromedia.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">2013-11-15 08:12:17</td>\n",
    "    <td class=\"tg-yw4l\">www.laposte.net</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">2013-11-15 08:12:17</td>\n",
    "    <td class=\"tg-yw4l\">www.google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">2013-11-15 08:12:18</td>\n",
    "    <td class=\"tg-yw4l\">www.laposte.net</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2part'></a>\n",
    "#### Создание сессий\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;На данном этапе поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. \n",
    "\n",
    "&#8195;Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов. Целевым классом будет id пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Отображение сайтов в их индексы выглядит так:\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "    <th class=\"tg-yw4l\">site_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">vk.com</td>\n",
    "    <td class=\"tg-yw4l\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "    <td class=\"tg-yw4l\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">yandex.ru</td>\n",
    "    <td class=\"tg-yw4l\">3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">facebook.com</td>\n",
    "    <td class=\"tg-yw4l\">4</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Для подготовки обучающей выборки реализована функция  prepare_train_set, которая принимает на вход путь к каталогу с csv-файлами path_to_csv_files и параметр session_length – длину сессии, а возвращает 2 объекта: \n",
    "- DataFrame, в котором строки соответствуют уникальным сессиям из session_length сайтов, session_length столбцов – индексам этих session_length сайтов и последний столбец – ID пользователя\n",
    "- частотный словарь сайтов вида {'site_string': [site_id, site_freq]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После применения функции получаем таблицу вида:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>site10</th>\n",
    "      <th>user_id</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>session_id</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>3</td>\n",
    "      <td>2</td>\n",
    "      <td>2</td>\n",
    "      <td>9</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>7</td>\n",
    "      <td>5</td>\n",
    "      <td>8</td>\n",
    "      <td>10</td>\n",
    "      <td>0001</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>3</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0001</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>3</td>\n",
    "      <td>2</td>\n",
    "      <td>6</td>\n",
    "      <td>6</td>\n",
    "      <td>2</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0002</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>4</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>5</td>\n",
    "      <td>11</td>\n",
    "      <td>4</td>\n",
    "      <td>0003</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>4</td>\n",
    "      <td>1</td>\n",
    "      <td>2</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0003</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "И словарь вида:\n",
    "\n",
    "     {'google.com': [1, 9],\n",
    "     'oracle.com': [2, 8],\n",
    "     'vk.com': [3, 3],\n",
    "     'meduza.io': [4, 3],\n",
    "     'mail.google.com': [5, 2],\n",
    "     'football.kulichki.ru': [6, 2],\n",
    "     'accounts.google.com': [7, 1],\n",
    "     'apis.google.com': [8, 1],\n",
    "     'geo.mozilla.org': [9, 1],\n",
    "     'plus.google.com': [10, 1],\n",
    "     'yandex.ru': [11, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3part'></a>\n",
    "#### Применение мешка слов\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Далее, что бы наши категориальные признаки с индексами сайтов приобрели смысл в рамках машинного обучения применим идею мешка слов. Точнее говоря не только идею, но и фактически преобразуем матрицы признаков в матрицу, где число столбцов равно количеству уникальных индексов сайтов, а в ячейках указано количество посещений того или иного сайта в рамках сессии.\n",
    "\n",
    "&#8195;Делать это будем с помощью разреженных матриц Scipy – csr_matrix. \n",
    "\n",
    "&#8195;Напишем функцию sparsecreator, которая приобразовывает массив с категориальными признаками в разряженную матрицу с вещественными.\n",
    "\n",
    "&#8195;Для 150 пользователей получим матрицу размером 137019x27797, где 27797 - число уникальных сайтов в выборке.\n",
    "\n",
    "&#8195;Полученная матрица:\n",
    "\n",
    "    matrix([[4, 2, 0, ..., 0, 0, 0],\n",
    "            [0, 1, 0, ..., 0, 0, 0],\n",
    "            [5, 1, 0, ..., 0, 0, 0],\n",
    "            ...,\n",
    "            [0, 0, 0, ..., 0, 0, 0],\n",
    "            [0, 0, 0, ..., 0, 0, 0],\n",
    "            [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4part'></a>\n",
    "#### Варьирование длины сессии и скользящее окно\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Пока мы брали последовательности из 10 сайтов. Далее сделаем число сайтов в сессии параметром, так что бы в дальнейшем сравнить модели классификации, обученные на разных выборках – с 5, 7, 10 и 15 сайтами в сессии. А так же применим идею скользящего окна – сессии будут перекрываться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Разработаем функцию prepare_sparse_train_set_window.\n",
    "\n",
    "&#8195;Аргументы:\n",
    "- path_to_csv_files – путь к каталогу с csv-файлами\n",
    "- site_freq_path – путь к pickle-файлу с частотным словарем, полученным в 1 части проекта\n",
    "- session_length – длина сессии (параметр)\n",
    "- window_size – ширина окна (параметр)\n",
    "\n",
    "&#8195;Значения:\n",
    "- разреженная матрица X_sparse (двухмерная Scipy.sparse.csr_matrix), в которой строки соответствуют сессиям из session_length сайтов, а max(site_id) столбцов – количеству посещений site_id в сессии.\n",
    "- вектор y (Numpy array) \"ответов\" в виде ID пользователей, которым принадлежат сессии из X_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Запустим созданную функцию со значениям параметра session_length (15, 10, 7, 5) и значениям параметра window_size (10, 7, 5) для выборки 10 и 150 пользователей. Сериализуем полученные 16 разреженных матриц (обучающие выборки) и вектора с метками целевого класса в файлы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3part'></a>\n",
    "### 3. Первичный анализ данных. Проверка гипотез\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Проверка гипотез будет осуществляться на матрице сессии-сайты с длинной сессии и окна 10 для выборки 10 пользователей.\n",
    "\n",
    "&#8195;Так выглядит ее структура:\n",
    "\n",
    "&nbsp;\n",
    "    \n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>site10</th>\n",
    "      <th>user_id</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>session_id</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>192</td>\n",
    "      <td>576</td>\n",
    "      <td>133</td>\n",
    "      <td>3</td>\n",
    "      <td>133</td>\n",
    "      <td>133</td>\n",
    "      <td>3</td>\n",
    "      <td>133</td>\n",
    "      <td>203</td>\n",
    "      <td>133</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>421</td>\n",
    "      <td>193</td>\n",
    "      <td>677</td>\n",
    "      <td>254</td>\n",
    "      <td>133</td>\n",
    "      <td>31</td>\n",
    "      <td>393</td>\n",
    "      <td>3403</td>\n",
    "      <td>217</td>\n",
    "      <td>55</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>55</td>\n",
    "      <td>3</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>5</td>\n",
    "      <td>293</td>\n",
    "      <td>421</td>\n",
    "      <td>333</td>\n",
    "      <td>899</td>\n",
    "      <td>55</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>473</td>\n",
    "      <td>3570</td>\n",
    "      <td>473</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>946</td>\n",
    "      <td>200</td>\n",
    "      <td>123</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>343</td>\n",
    "      <td>55</td>\n",
    "      <td>5</td>\n",
    "      <td>3399</td>\n",
    "      <td>258</td>\n",
    "      <td>212</td>\n",
    "      <td>3498</td>\n",
    "      <td>2095</td>\n",
    "      <td>674</td>\n",
    "      <td>2095</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Распределение целевого класса:\n",
    "    \n",
    "    128    2796\n",
    "    39     2204\n",
    "    207    1868\n",
    "    127    1712\n",
    "    237    1643\n",
    "    33     1022\n",
    "    50      802\n",
    "    31      760\n",
    "    100     720\n",
    "    241     534\n",
    "    Name: user_id, dtype: int64\n",
    "    \n",
    "&#8195;Посчитаем распределение числа уникальных сайтов в каждой сессии из 10 посещенных подряд сайтов:\n",
    "\n",
    "    7     2308\n",
    "    6     2197\n",
    "    8     2046\n",
    "    5     1735\n",
    "    9     1394\n",
    "    2     1246\n",
    "    4     1163\n",
    "    3      894\n",
    "    10     651\n",
    "    1      427\n",
    "    dtype: int64\n",
    " \n",
    " &nbsp;\n",
    " \n",
    "![](image1.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Для проверки нормальности рапределения числа уникальных сайтов воспользуемся критерием Шапиро-Уилка и построим QQ-график.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    " ![](image2.png)\n",
    " \n",
    " &nbsp;\n",
    " \n",
    "&#8195;Критерий на данной выборке показывает p-value близкое к нулю, на QQ-графике видны длинные хвосты, т.е. имеется перекос в сторону больших и минимальных значений. Число уникальных сайтов распределено не нормально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Проверим с помощью биномиального критерия для доли, что доля случаев, когда пользователь повторно посетил какой-то сайт (то есть число уникальных сайтов в сессии < 10) велика: больше 95%.\n",
    "\n",
    "&#8195;Полученное p-value 0.022\n",
    "\n",
    "&#8195;95% доверительный интервал Уилсона для доли случаев, когда пользователь повторно посетил какой-то сайт:\n",
    "\n",
    "(0.9501028841411286, 0.9570527377232229)\n",
    "\n",
    "&#8195;На основании этих результатов можно уверенно предположить, что пользователи склонны посещать сайты (сайт) повторно в рамках сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Постром распределение частоты посещения сайтов для сайтов, которые были посещены как минимум 1000 раз.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![ss](image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Построим 95% доверительный интервал для средней частоты появления сайта в выборке на основе bootstrap. Используем столько же bootstrap-подвыборок, сколько сайтов оказалось в исходной выборке по 10 пользователям (получим массив 4913 Х 4913).\n",
    "\n",
    "&#8195;Полученный интервал средней частоты появления сайта в выборке: (22.51524527, 35.76303684)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4part'></a>\n",
    "### 4. Разработка признаков и их визуальный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1part'></a>\n",
    "#### Временные признаки и количество уникальных сайтов\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;У нас уже есть признаки - индексы сайтов в сессиях. Добавим к ним следующие признаки:\n",
    "- session_timespan – продолжительность сессии (разница между максимальным и минимальным временем посещения сайтов в сессии, в секундах)\n",
    "- #unique_sites – число уникальных сайтов в сессии\n",
    "- start_hour – час начала сессии (то есть час в записи минимального timestamp среди десяти)\n",
    "- day_of_week – день недели (то есть день недели в записи минимального timestamp среди десяти)\n",
    "- time_diff# где # - номер сайта, временной промежуток между посещениями сайтов (в секундах)\n",
    "\n",
    "&#8195;Получим таблицу следующего вида:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>site10</th>\n",
    "      <th>time_diff1</th>\n",
    "      <th>time_diff2</th>\n",
    "      <th>time_diff3</th>\n",
    "      <th>time_diff4</th>\n",
    "      <th>time_diff5</th>\n",
    "      <th>time_diff6</th>\n",
    "      <th>time_diff7</th>\n",
    "      <th>time_diff8</th>\n",
    "      <th>time_diff9</th>\n",
    "      <th>session_timespan</th>\n",
    "      <th>#unique_sites</th>\n",
    "      <th>start_hour</th>\n",
    "      <th>day_of_week</th>\n",
    "      <th>target</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>192</td>\n",
    "      <td>576</td>\n",
    "      <td>133</td>\n",
    "      <td>3</td>\n",
    "      <td>133</td>\n",
    "      <td>133</td>\n",
    "      <td>3</td>\n",
    "      <td>133</td>\n",
    "      <td>203</td>\n",
    "      <td>133</td>\n",
    "      <td>10</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>20</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>33</td>\n",
    "      <td>5</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>421</td>\n",
    "      <td>193</td>\n",
    "      <td>677</td>\n",
    "      <td>254</td>\n",
    "      <td>133</td>\n",
    "      <td>31</td>\n",
    "      <td>393</td>\n",
    "      <td>3403</td>\n",
    "      <td>217</td>\n",
    "      <td>55</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>163</td>\n",
    "      <td>105</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>3</td>\n",
    "      <td>3</td>\n",
    "      <td>8</td>\n",
    "      <td>284</td>\n",
    "      <td>10</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>55</td>\n",
    "      <td>3</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>5</td>\n",
    "      <td>293</td>\n",
    "      <td>421</td>\n",
    "      <td>333</td>\n",
    "      <td>899</td>\n",
    "      <td>55</td>\n",
    "      <td>0</td>\n",
    "      <td>14</td>\n",
    "      <td>1</td>\n",
    "      <td>242</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>258</td>\n",
    "      <td>7</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>473</td>\n",
    "      <td>3570</td>\n",
    "      <td>473</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>946</td>\n",
    "      <td>200</td>\n",
    "      <td>123</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>25</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>30</td>\n",
    "      <td>6</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>343</td>\n",
    "      <td>55</td>\n",
    "      <td>5</td>\n",
    "      <td>3399</td>\n",
    "      <td>258</td>\n",
    "      <td>212</td>\n",
    "      <td>3498</td>\n",
    "      <td>2095</td>\n",
    "      <td>674</td>\n",
    "      <td>2095</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>6</td>\n",
    "      <td>9</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Для выборки 150 пользователей расчитаем также некоторые другие показатели:\n",
    "- Медианный день недели, в который началась сессия: 2\n",
    "- Медианный час начала сессии: 13\n",
    "- Медианное значение числа уникальных сайтов в сессиях: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Дадим пользователям имена и ассоциируем с ними цвета и посмотрим на некоторые распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Распределение длины сессии в секундах</center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![ss](image4.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Распределения числа уникальных сайтов (#unique_sites) в сессии для каждого из 10 пользователей</center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "![ss](image5.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Распределения часа начала сессии (start_hour) для каждого из 10 пользователей</center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![ss](image6.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Распределения дня недели, в который началась сессия (day_of_week) для каждого из 10 пользователей</center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![ss](image7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2part'></a>\n",
    "#### Вывод для каждого пользователя по построенным признакам\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Сделаем вывод для каждого пользователя.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Ashley\n",
    "\n",
    "&#8195;В сессии чаще всего 7 сайтов. Группировка вокруг 7ми с крупным выбросом на единице.\n",
    "Намного больше сессий приходится на ранее утро.\n",
    "Среда - любимый день. Суббота и воскресенье - нерабочие дни.\n",
    "В сессии чаще всего 6 сайтов. Группировка вокруг 6ти.\n",
    "\n",
    "&#8195;Avril\n",
    "\n",
    "&#8195;Пики рабочего процесса в интернете приходятся на 15:00 и 17:00. Напомиает гауссиану с провалами.\n",
    "Вторник - пик частоты активности. Среда, четверг, воскресенье - дни более частой активности.\n",
    "\n",
    "&#8195;Bill\n",
    "\n",
    "&#8195;Большинство сессий приходятся на 15:00, в два раза меньше, но тоже значительное количество на 8:30.\n",
    "Понедельник, вторник - дни наиболее вероятной активности.\n",
    "\n",
    "&#8195;Bob\n",
    "\n",
    "&#8195;В сессии чаще всего 6 сайтов. Группировка вокруг 6ти со скосом в большую сторону.\n",
    "Больше сессий с утра, да и вообще много сессий.\n",
    "Вторник, чертверг, пятница- наиболее часто активные дни. Суббота и воскресенье - нерабочие дни.\n",
    "\n",
    "&#8195;Dick\n",
    "\n",
    "&#8195;Более-менее равномерное распределение сессий с тремя пиками\n",
    "Понедельник, среда - редкая активность. Пятница - пик частоты активности. Далее частоты активности по убыванию: вторик, четверг, суббота. Воскресение - нерабочий день.\n",
    "\n",
    "&#8195;Ed\n",
    "\n",
    "&#8195;В сессии чаще всего 7 или 8 сайтов, так же очень часто 6. Далее по нисходящей.\n",
    "Пик начала сессий на середине дня, сессий сравнительно немного. Напомиает гауссиану с крупными выбросами.\n",
    "Среда, суббота, воскресение - пики частоты активности. Топ в среду. \n",
    "\n",
    "&#8195;John\n",
    "\n",
    "&#8195;В сессии чаще всего 7 сайтов. Группировка вокруг 7ти со скосом в большую сторону.\n",
    "Основные сессии приходятся на рабочие часы с пиками на 11 и 15 часов.\n",
    "Частая активность во все рабочие дни со скосом в сторону пятницы. Суббота редкая активность. Воскресение - нерабочий день.\n",
    "\n",
    "\n",
    "&#8195;Lindsey\n",
    "\n",
    "&#8195;В сессии чаще всего 7 сайтов. Группировка вокруг 7ти со скосом в большую сторону.\n",
    "Сессии сдвинуты в сторону первой половины дня.\n",
    "Вторник - пик частоты активности. Далее по нисходящей до понедельника.\n",
    "\n",
    "&#8195;Mary-Kate\n",
    "\n",
    "&#8195;В сессии чаще всего 3 сайта. Минимальное количество с одним уникальным сайтом. В остальном распределением более-менее равномерное.\n",
    "В целом больше сессий в сравнении с другими, при чем пик на вечернее время.\n",
    "Суббота, воскресенье - концентраторы активности.\n",
    "\n",
    "&#8195;Naomi\n",
    "\n",
    "&#8195;В сессии чаще всего 6 сайтов. Группировка вокруг 6ти со скосом в большую сторону.\n",
    "Пик сессий на 11 утра, 11-18 наиболее активное время.\n",
    "Четверг - концентратор активности, далее вторник и среда."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Топ 10 посещаемых сайтов</center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![ss](image8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3part'></a>\n",
    "#### Признаки \"работает или развлекается пользователь\"\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Далее в рамках творческого подхода, в качестве критерия идентификации пользователя попробуем определять то, сколько что человек чаще делает: работает или развлекается. Конечно критерий сложный, но мы его только попытаемся симитировать.\n",
    "\n",
    "&#8195;Для подсчета такого критерия мы можем считать факты частоту посещения определенных сайтов. Например почту можно считать условно за работу, а ютьюб за развлечения. С другой стороны ютьюб является наиболее частопосещаемым сайтом (очевидно, что люди в принципе предпочитают развлекаться), поэтому признак на его основе скорее может получиться неинформативным. Поэтому попробуем посчитать почту, ютьюб и фейсбук. Опять же фейсбук может быть связан с работой, но условно, с некоторыми допущениями, его все-таки можно взять в рубрику \"я сейчас не работаю\"\n",
    "\n",
    "&#8195;В качестве признаков будем считать:\n",
    "\n",
    "- Было ли посещение почтового ящика на mail.google.com\n",
    "- Было ли посещение youtube\n",
    "- Было ли посещение фейсбука\n",
    "- Какова средняя длина сессиии на топ 30 сайтах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Внешний вид массива с признаками:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "  <table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>mail</th>\n",
    "      <th>facebook</th>\n",
    "      <th>top30_av_time</th>\n",
    "      <th>youtube</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0.5</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>7.0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Таблица со всеми признаками:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>site10</th>\n",
    "      <th>time_diff1</th>\n",
    "      <th>time_diff2</th>\n",
    "      <th>...</th>\n",
    "      <th>time_diff7</th>\n",
    "      <th>time_diff8</th>\n",
    "      <th>time_diff9</th>\n",
    "      <th>session_timespan</th>\n",
    "      <th>#unique_sites</th>\n",
    "      <th>start_hour</th>\n",
    "      <th>day_of_week</th>\n",
    "      <th>mail</th>\n",
    "      <th>facebook</th>\n",
    "      <th>top30_av_time</th>\n",
    "      <th>youtube</th>\n",
    "      <th>target</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>192</td>\n",
    "      <td>576</td>\n",
    "      <td>133</td>\n",
    "      <td>3</td>\n",
    "      <td>133</td>\n",
    "      <td>133</td>\n",
    "      <td>3</td>\n",
    "      <td>133</td>\n",
    "      <td>203</td>\n",
    "      <td>133</td>\n",
    "      <td>10</td>\n",
    "      <td>0</td>\n",
    "      <td>...</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>33</td>\n",
    "      <td>5</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0.5</td>\n",
    "      <td>0</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>421</td>\n",
    "      <td>193</td>\n",
    "      <td>677</td>\n",
    "      <td>254</td>\n",
    "      <td>133</td>\n",
    "      <td>31</td>\n",
    "      <td>393</td>\n",
    "      <td>3403</td>\n",
    "      <td>217</td>\n",
    "      <td>55</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>...</td>\n",
    "      <td>3</td>\n",
    "      <td>3</td>\n",
    "      <td>8</td>\n",
    "      <td>284</td>\n",
    "      <td>10</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>55</td>\n",
    "      <td>3</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>5</td>\n",
    "      <td>293</td>\n",
    "      <td>421</td>\n",
    "      <td>333</td>\n",
    "      <td>899</td>\n",
    "      <td>55</td>\n",
    "      <td>0</td>\n",
    "      <td>14</td>\n",
    "      <td>...</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>258</td>\n",
    "      <td>7</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>7.0</td>\n",
    "      <td>0</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>473</td>\n",
    "      <td>3570</td>\n",
    "      <td>473</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>55</td>\n",
    "      <td>946</td>\n",
    "      <td>200</td>\n",
    "      <td>123</td>\n",
    "      <td>2</td>\n",
    "      <td>1</td>\n",
    "      <td>...</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>30</td>\n",
    "      <td>6</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>343</td>\n",
    "      <td>55</td>\n",
    "      <td>5</td>\n",
    "      <td>3399</td>\n",
    "      <td>258</td>\n",
    "      <td>212</td>\n",
    "      <td>3498</td>\n",
    "      <td>2095</td>\n",
    "      <td>674</td>\n",
    "      <td>2095</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>...</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>6</td>\n",
    "      <td>9</td>\n",
    "      <td>8</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0</td>\n",
    "      <td>31</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Посмотрим на графики распределений построенных признаков.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Признак 'mail'</center>\n",
    "\n",
    "![](image9.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Признак 'youtube'</center>\n",
    "\n",
    "![](image10.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Признак 'facebook'</center>\n",
    "\n",
    "![](image11.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Среднее время на топ-30 сайтов для каждого из 10 пользователей</center>\n",
    "\n",
    "![](image12.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Мы видим, что графики посещений сайтов значительно различаются, что может свидетельстовать о том, что нам удастся лучше идентифицировать пользователей с использованием такого набора дополнительных признаков. Среднее посещение сайта так же варьируется от пользователя к пользователю, а значит несет в себе информацию.\n",
    "\n",
    "&#8195;В дальнейшем признаки будут протестированы на моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5part'></a>\n",
    "### 5. Сравнение алгоритмов и подбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Далее сравним на кросс-валидации несколько алгоритмов, разберемся, какие параметры длины сессии (session_length и window_size) работают эффективннее.\n",
    "\n",
    "&#8195;Также для выбранного алгоритма проверим влияние дополнительных признаков на качество классификации, построим кривые валидации (как качество классификации зависит от одного из гиперпараметров алгоритма) и кривые обучения (как качество классификации зависит от объема выборки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1part'></a>\n",
    "#### Сравнение нескольких алгоритмов на сессиях из 10 сайтов\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Разобьем выборку на 2 части. На одной будем проводить кросс-валидацию, на второй – оценивать модель, обученную после кросс-валидации.\n",
    "\n",
    "&#8195;Тип кросс-валидации: 3-кратная, с перемешиванием, random_state=17.\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Обучим алгоритмы K-ближайших соседей, случайный лес, логистическую регрессию и метод опорных векторов с большинством гиперпараметров по-умолчанию. Параметры, а так же соответствующие значения метрик на кросс-валидации и на отложенной выборке приведены в таблице ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\" style=\"undefined;table-layout: fixed; width: 700px\">\n",
    "<colgroup>\n",
    "<col style=\"width: 200px\">\n",
    "<col style=\"width: 151px\">\n",
    "<col style=\"width: 180px\">\n",
    "</colgroup>\n",
    "  <tr>\n",
    "    <th class=\"tg-0lax\">Алгоритм</th>\n",
    "    <th class=\"tg-baqh\"><span style=\"font-weight:700\">Accuracy</span><br><br><br><span style=\"font-weight:700\">на кросс-валидации</span></th>\n",
    "    <th class=\"tg-baqh\"><span style=\"font-weight:700\">Accuracy</span><br><br><br><span style=\"font-weight:700\">на отложенной выборке</span></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">KNeighborsClassifier(n_neighbors=100)</td>\n",
    "    <td class=\"tg-c3ow\">0.565</td>\n",
    "    <td class=\"tg-c3ow\">0.584</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">RandomForestClassifier(n_estimators=100,<br>random_state=17, oob_score=True)</td>\n",
    "    <td class=\"tg-c3ow\">0.721</td>\n",
    "    <td class=\"tg-c3ow\">0.73</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">LogisticRegression(random_state=17)</td>\n",
    "    <td class=\"tg-c3ow\">0.761</td>\n",
    "    <td class=\"tg-c3ow\">0.782</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">LinearSVC(C=1, random_state=17)</td>\n",
    "    <td class=\"tg-baqh\">0.753</td>\n",
    "    <td class=\"tg-baqh\">0.777</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Далее подберем гиперпараметр C, который отвечает за регуляризацию у логистической регрессии и SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4850f004cd547389a08864bf287a332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01w\\x00\\x00\\x00\\xfc\\x08\\x06\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('image13.png', 'rb') as f:\n",
    "    img13 = f.read()\n",
    "with open('image14.png', 'rb') as f:\n",
    "    img14 = f.read()\n",
    "with open('image15.png', 'rb') as f:\n",
    "    img15 = f.read()\n",
    "with open('image16.png', 'rb') as f:\n",
    "    img16 = f.read()\n",
    "accordion = widgets.Accordion(children=[widgets.Image(value=img13), widgets.Image(value=img14),\n",
    "                              widgets.Image(value=img15), widgets.Image(value=img16)])\n",
    "accordion.set_title(0, 'Кривая валидации для значений C логистической регрессии в диапазоне 1e-4 до 1e2:')\n",
    "accordion.set_title(1, 'Кривая валидации для значений C логистической регрессии в диапазоне 0.1 до 7:')\n",
    "accordion.set_title(2, 'Кривая валидации для значений C алгоритма SVM в диапазоне 1e-4 до 1e4:')\n",
    "accordion.set_title(3, 'Кривая валидации для значений C алгоритма SVM в диапазоне 1e-3 до 1')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = widgets.SelectionSlider(\n",
    "    options=['1e-4 : 1e2', '0.1 : 7'],\n",
    "    value='1e-4 : 1e2',\n",
    "    description='C in range',\n",
    "    disabled=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "def f1(x):\n",
    "    if x == '1e-4 : 1e2':\n",
    "        accuracy, C = 0.7610, 2.782\n",
    "    if x == '0.1 : 7':\n",
    "        accuracy, C, accuracyvalid = 0.7613, 1.553, 0.784\n",
    "        print('Лучшее значение доли на отложенной выборке: {}'.format(accuracyvalid))\n",
    "    print('Лучшее значение доли на CV: {}'.format(accuracy))\n",
    "    print('C при максимальном значении доли: {}'.format(C))\n",
    "    \n",
    "w2 = widgets.SelectionSlider(\n",
    "    options=['1e-4 : 1e2', '1e-3 : 1'],\n",
    "    value='1e-4 : 1e2',\n",
    "    description='C in range',\n",
    "    disabled=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "def f2(x):\n",
    "    if x == '1e-4 : 1e2':\n",
    "        accuracy, C = 0.685, 3333.333\n",
    "    if x == '1e-3 : 1':\n",
    "        accuracy, C, accuracyvalid = 0.765, 0.104, 0.781\n",
    "        print('Лучшее значение доли на отложенной выборке: {}'.format(accuracyvalid))\n",
    "        \n",
    "    print('Лучшее значение доли на CV: {}'.format(accuracy))\n",
    "    print('C при максимальном значении доли: {}'.format(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор параметров для logregression:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a45d367c1f74e0980053c65dab2c760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='C in range', options=('1e-4 : 1e2', '0.1 : 7'), value='1e-4…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбор параметров для SVM:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cef6c1e953f4648a4f21bdb8d98c499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='C in range', options=('1e-4 : 1e2', '1e-3 : 1'), value='1e-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Подбор параметров для logregression:')\n",
    "interact(f1, x=w1);\n",
    "print('Подбор параметров для SVM:')\n",
    "interact(f2, x=w2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;SMV показывает лучший результат на кросс-валидации, при проигрыше на отложенной выборке. Так или иначе далее поработаем с SVM в процессе подбора оптимальной длины сессии и ширины окна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.2part'></a>\n",
    "#### Выбор параметров – длины сессии и ширины окна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Определим функцию model_assessment, с помощью которой измерим метрику accuracy при различных длинах сессии и ширины окна.\n",
    "\n",
    "&#8195;Применять функцию будем к модели SVM с параметром C = 0.104 (давшем лучшее качество на кросс-валидации).\n",
    "\n",
    "&#8195;Ниже представлен отчет по проведенному перебору."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Результаты для выборок 10 и 150 пользователей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b472fad399264fd497b5a548f0c47db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='10 us. sample:', options=('Лучший вариант', 'Список переборов…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a638a2dbfd1445c6b5faa7c94e1878ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='150 us. sample:', options=('Лучший вариант', 'Список переборо…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10 users:\n",
    "\n",
    "with open('report_10users_logreg_c_select.txt') as f:\n",
    "    lst = f.readlines()\n",
    "with open('report_10users_logreg_c_select_best.txt') as f:\n",
    "    best = f.readlines()\n",
    "w3 = widgets.ToggleButtons(\n",
    "    options=['Лучший вариант', 'Список переборов'],\n",
    "    description='10 us. sample:',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
    "#     icons=['check'] * 3\n",
    ")\n",
    "\n",
    "def f3(x):\n",
    "    if x == 'Список переборов':\n",
    "        for i in lst:\n",
    "            print(i)\n",
    "    if x == 'Лучший вариант':\n",
    "        for i in best:\n",
    "            print(i)\n",
    "            \n",
    "interact(f3, x=w3);\n",
    "\n",
    "# 150 users:\n",
    "\n",
    "with open('report_150users_logreg_c_select.txt') as f:\n",
    "    lst2 = f.readlines()\n",
    "with open('report_150users_logreg_c_select_best.txt') as f:\n",
    "    best2 = f.readlines()\n",
    "w4 = widgets.ToggleButtons(\n",
    "    options=['Лучший вариант', 'Список переборов'],\n",
    "    description='150 us. sample:',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
    "#     icons=['check'] * 3\n",
    ")\n",
    "\n",
    "def f4(x):\n",
    "    if x == 'Список переборов':\n",
    "        for i in lst2:\n",
    "            print(i)\n",
    "    if x == 'Лучший вариант':\n",
    "        for i in best2:\n",
    "            print(i)\n",
    "            \n",
    "interact(f4, x=w4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;На выборке 10 пользователей заметно, что увеличение длины сессии и уменьшение ширины окна увеличивает качество на кросс-валидации и отложенной выборке. Что логично, учитывая что при таких параметрах получается выборка максимального размера.\n",
    "\n",
    "&#8195;Кроме того качество многоклассовой классификации на выборке 150 пользователей оставляет желать много лучшего. Поэтому следующим этапом станет идентификация конкретного пользователя или бинарная классификация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.3part'></a>\n",
    "#### Идентификация конкретного пользователя и кривые обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Обучим LogisticRegressionCV с C = 1.553 (лучшим на кросс-валидации для 10 пользователей). \n",
    "\n",
    "&#8195;Посмотрим на средние доли правильных ответов на кросс-валидации в задаче идентификации каждого пользователя по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запустите ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f3572a6de449499090f69fa6debcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Textarea(value='User 0006, CV score: 0.9960795612888451\\nUser 0013, CV score: 0.9963926034…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('report_150users_logreg_ovr_predict.txt') as f:\n",
    "     lst = f.read()\n",
    "accordion = widgets.Accordion(children=[widgets.Textarea(lst)])\n",
    "accordion.set_title(0, 'Доли правильных ответов на кросс-валидации по пользователям')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Стоит помнить про имеющийся дисбаланс классов, так что высокую долю правильных ответов можно получить константным прогнозом. \n",
    "\n",
    "&#8195;Проверим лучше ли имеющийся алгоритм константного. Для этого посчитаем для каждого пользователя разницу между долей правильных ответов на кросс-валидации и долей меток в y_train_150, отличных от ID этого пользователя (именно такую долю правильных ответов можно получить, если классификатор всегда \"говорит\", что это не пользователь с номером 𝑖 в задаче классификации 𝑖-vs-All).\n",
    "\n",
    "&#8195;Доля пользователей, для которых логистическая регрессия на кросс-валидации дает прогноз лучше константного: \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Построим кривую обучения, что бы понять, можно ли улучшить качество классификации, увеличив выборку.\n",
    "\n",
    "&#8195;Таким образом посчитаем доли правильных ответов на кросс-валидации в задаче классификации \"user128-vs-All\" в зависимости от размера выборки с помощью learning_curve и посмотрим на график plot_learning_curve.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![ss](image17.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;По графику наблюдается прекращение роста кривой при 50000 значениях в выборке, улучшение результата при дальнейшем увеличении выборки является маловероятным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6part'></a>\n",
    "### 6. Соревнование Kaggle\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<a id='6.1part'></a>\n",
    "#### Анализ и подготовка данных\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;В обучающей выборке видим следующие признаки:\n",
    "\n",
    "- site1 – индекс первого посещенного сайта в сессии\n",
    "- time1 – время посещения первого сайта в сессии\n",
    "- ...\n",
    "- site10 – индекс 10-го посещенного сайта в сессии\n",
    "- time10 – время посещения 10-го сайта в сессии\n",
    "- user_id – ID пользователя\n",
    "&#8195;Сессии пользователей выделены таким образом, что они не могут быть длинее получаса или 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд, либо когда сессия заняла по времени более 30 минут.\n",
    "\n",
    "&#8195;В тестовой выборке все тоже самое, просто без столбца user_id.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Посмотрим на статистику признаков.\n",
    "\n",
    "&#8195;Пропуски возникают там, где сессии короткие (менее 10 сайтов). Скажем, если человек 1 января 2015 года посетил vk.com в 20:01, потом yandex.ru в 20:29, затем google.com в 20:33, то первая его сессия будет состоять только из двух сайтов (site1 – ID сайта vk.com, time1 – 2015-01-01 20:01:00, site2 – ID сайта yandex.ru, time2 – 2015-01-01 20:29:00, остальные признаки – NaN), а начиная с google.com пойдет новая сессия, потому что уже прошло более 30 минут с момента посещения vk.com.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;В обучающей выборке – 2297 сессий одного пользователя (Alice) и 251264 сессий – других пользователей, не Элис. Дисбаланс классов очень сильный, и смотреть на долю верных ответов (accuracy) непоказательно.\n",
    "\n",
    "&#8195;Пока для прогноза будем использовать только индексы посещенных сайтов. Индексы нумеровались с 1, так что заменим пропуски на нули.\n",
    "\n",
    "&#8195;Получим таблицу:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>site10</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>session_id</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>718</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>890</td>\n",
    "      <td>941</td>\n",
    "      <td>3847</td>\n",
    "      <td>941</td>\n",
    "      <td>942</td>\n",
    "      <td>3846</td>\n",
    "      <td>3847</td>\n",
    "      <td>3846</td>\n",
    "      <td>1516</td>\n",
    "      <td>1518</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>14769</td>\n",
    "      <td>39</td>\n",
    "      <td>14768</td>\n",
    "      <td>14769</td>\n",
    "      <td>37</td>\n",
    "      <td>39</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>22</td>\n",
    "      <td>177</td>\n",
    "      <td>175</td>\n",
    "      <td>178</td>\n",
    "      <td>177</td>\n",
    "      <td>178</td>\n",
    "      <td>175</td>\n",
    "      <td>177</td>\n",
    "      <td>177</td>\n",
    "      <td>178</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>570</td>\n",
    "      <td>21</td>\n",
    "      <td>570</td>\n",
    "      <td>21</td>\n",
    "      <td>21</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>803</td>\n",
    "      <td>23</td>\n",
    "      <td>5956</td>\n",
    "      <td>17513</td>\n",
    "      <td>37</td>\n",
    "      <td>21</td>\n",
    "      <td>803</td>\n",
    "      <td>17514</td>\n",
    "      <td>17514</td>\n",
    "      <td>17514</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>22</td>\n",
    "      <td>21</td>\n",
    "      <td>29</td>\n",
    "      <td>5041</td>\n",
    "      <td>14422</td>\n",
    "      <td>23</td>\n",
    "      <td>21</td>\n",
    "      <td>5041</td>\n",
    "      <td>14421</td>\n",
    "      <td>14421</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>668</td>\n",
    "      <td>940</td>\n",
    "      <td>942</td>\n",
    "      <td>941</td>\n",
    "      <td>941</td>\n",
    "      <td>942</td>\n",
    "      <td>940</td>\n",
    "      <td>23</td>\n",
    "      <td>21</td>\n",
    "      <td>22</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>3700</td>\n",
    "      <td>229</td>\n",
    "      <td>570</td>\n",
    "      <td>21</td>\n",
    "      <td>229</td>\n",
    "      <td>21</td>\n",
    "      <td>21</td>\n",
    "      <td>21</td>\n",
    "      <td>2336</td>\n",
    "      <td>2044</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2part'></a>\n",
    "#### Первый сабмит\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Создадим из тестовой и обучающей выборок разреженные матрицы X_train_sparse и X_test_sparse аналогичным образом как ранее, что бы использовать индексы сайтов как признаки. Столбец обучающей выборки с целевыми метками выведем в отдельный вектор.\n",
    "\n",
    "&#8195;Обратим внимание и на то, что в сессиях меньше 10 сайтов у нас остались нули, так что первый признак (сколько раз попался 0) по смыслу отличен от остальных. Поэтому первый столбец разреженной матрицы удалим.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "<center>Размерности полученных матриц\n",
    "    \n",
    "&nbsp;\n",
    "\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-cly1{text-align:left;vertical-align:middle}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-cly1\"></th>\n",
    "    <th class=\"tg-cly1\">Строк</th>\n",
    "    <th class=\"tg-cly1\">Столбцов</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-cly1\">Обучающая выборка</td>\n",
    "    <td class=\"tg-cly1\">253561 </td>\n",
    "    <td class=\"tg-cly1\">48370</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-cly1\">Тестовая выборка</td>\n",
    "    <td class=\"tg-cly1\">82797 </td>\n",
    "    <td class=\"tg-cly1\">48370</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Разобьем обучающую выборку на 2 части в пропорции 7/3, причем не перемешивая. Исходные данные упорядочены по времени, тестовая выборка по времени четко отделена от обучающей, сохраним теже условия.\n",
    "\n",
    "    train_share = int(.7 * X_train_sparse.shape[0])\n",
    "    X_train, y_train = X_train_sparse[:train_share, :], y[:train_share]\n",
    "    X_valid, y_valid  = X_train_sparse[train_share:, :], y[train_share:]\n",
    "\n",
    "&#8195;Получим соответствующие пары  X_train, y_train и X_valid, y_valid.\n",
    "\n",
    "&#8195;Создадим объект sklearn.linear_model.SGDClassifier с логистической функцией потерь. Остальные параметры оставим по умолчанию. \n",
    "Обучим модель на выборке (X_train, y_train), сделаем предсказание на (X_valid, y_valid).\n",
    "    \n",
    "    sgd_logit = SGDClassifier(loss='log', random_state=17, n_jobs=-1)\n",
    "    sgd_logit.fit(X_train, y_train)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>roc_auc_score = 0.934"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Сформируем прогноз для отправки на kaggle: cделаем прогноз в виде предсказанных вероятностей (predict_proba) отнесения к классу 1 для тестовой выборки с помощью той же модели, но обученной уже на всей обучающей выборке.\n",
    "Отправим прогноз на kaggle от имени команды '[YDF & MIPT] Coursera_Dmi2ry'\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Оценка kaggle = 0.91275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.3part'></a>\n",
    "#### Второй сабмит\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Обучим логрегрессию на выборке с дополнительными признаками.\n",
    "\n",
    "&#8195;Для начала добавим четыре признака, которые мы уже однажды тестировали в части 4:\n",
    "- 'session_timespan' - длина сессии\n",
    "- 'day_of_week' - день старта сессии\n",
    "- 'start_hour' - час старта сессии\n",
    "- 'unique_sites' - количество уникальных сайтов в сессии\n",
    "\n",
    "&#8195;Создадим функцию, которая посчитает вышеперечисленные признаки и сформирует матрицу. На вход будем подавать train_test_df из конкатенированных ранее матриц train_sessions.csv и test_sessions.csv, на выходе будем получать матрицу следующего вида:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site10</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>...</th>\n",
    "      <th>time4</th>\n",
    "      <th>time5</th>\n",
    "      <th>time6</th>\n",
    "      <th>time7</th>\n",
    "      <th>time8</th>\n",
    "      <th>time9</th>\n",
    "      <th>session_timespan</th>\n",
    "      <th>day_of_week</th>\n",
    "      <th>start_hour</th>\n",
    "      <th>unique_sites</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>session_id</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>718</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>...</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>3</td>\n",
    "      <td>10</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>890</td>\n",
    "      <td>1518</td>\n",
    "      <td>941</td>\n",
    "      <td>3847</td>\n",
    "      <td>941</td>\n",
    "      <td>942</td>\n",
    "      <td>3846</td>\n",
    "      <td>3847</td>\n",
    "      <td>3846</td>\n",
    "      <td>1516</td>\n",
    "      <td>...</td>\n",
    "      <td>2014-02-22 11:19:51</td>\n",
    "      <td>2014-02-22 11:19:51</td>\n",
    "      <td>2014-02-22 11:19:51</td>\n",
    "      <td>2014-02-22 11:19:52</td>\n",
    "      <td>2014-02-22 11:19:52</td>\n",
    "      <td>2014-02-22 11:20:15</td>\n",
    "      <td>26</td>\n",
    "      <td>5</td>\n",
    "      <td>11</td>\n",
    "      <td>7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>14769</td>\n",
    "      <td>14768</td>\n",
    "      <td>39</td>\n",
    "      <td>14768</td>\n",
    "      <td>14769</td>\n",
    "      <td>37</td>\n",
    "      <td>39</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "      <td>...</td>\n",
    "      <td>2013-12-16 16:40:19</td>\n",
    "      <td>2013-12-16 16:40:19</td>\n",
    "      <td>2013-12-16 16:40:19</td>\n",
    "      <td>2013-12-16 16:40:20</td>\n",
    "      <td>2013-12-16 16:40:21</td>\n",
    "      <td>2013-12-16 16:40:22</td>\n",
    "      <td>7</td>\n",
    "      <td>0</td>\n",
    "      <td>16</td>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>...</td>\n",
    "      <td>2014-03-28 10:53:42</td>\n",
    "      <td>2014-03-28 10:54:12</td>\n",
    "      <td>2014-03-28 10:54:42</td>\n",
    "      <td>2014-03-28 10:55:12</td>\n",
    "      <td>2014-03-28 10:55:42</td>\n",
    "      <td>2014-03-28 10:56:12</td>\n",
    "      <td>270</td>\n",
    "      <td>4</td>\n",
    "      <td>10</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>22</td>\n",
    "      <td>178</td>\n",
    "      <td>177</td>\n",
    "      <td>175</td>\n",
    "      <td>178</td>\n",
    "      <td>177</td>\n",
    "      <td>178</td>\n",
    "      <td>175</td>\n",
    "      <td>177</td>\n",
    "      <td>177</td>\n",
    "      <td>...</td>\n",
    "      <td>2014-02-28 10:55:23</td>\n",
    "      <td>2014-02-28 10:55:23</td>\n",
    "      <td>2014-02-28 10:55:59</td>\n",
    "      <td>2014-02-28 10:55:59</td>\n",
    "      <td>2014-02-28 10:55:59</td>\n",
    "      <td>2014-02-28 10:57:06</td>\n",
    "      <td>246</td>\n",
    "      <td>4</td>\n",
    "      <td>10</td>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Преобразуем получившиеся признаки так, что на них можно обучаться - ведь в матрице выше мы имеем категориальные, на которых методы машинного обучения не работают. Для признаков-сайтов используем уже неоднократно используювшуюся функцию sparsecreator, а для преобразования вновь созданных признаков будет удобно применить pd.get_dummies\n",
    "\n",
    "    X_sparse = sparsecreator(X.iloc[:, :10].values)\n",
    "    X_sparse = X_sparse[:, 1:]\n",
    "    dummies = pd.get_dummies(X.iloc[:, -4:], sparse=True, columns=['start_hour', 'unique_sites', 'day_of_week','session_timespan'])\n",
    "    X_sparse_dum = hstack([X_sparse, csr_matrix(dummies)], format='csr')\n",
    "    \n",
    "&#8195;Разделим X_sparse_dum на обучение и тест:\n",
    " \n",
    "    X_train_sparse = X_sparse_dum[:253561]\n",
    "    X_test_sparse = X_sparse_dum[253561:]\n",
    "    \n",
    "&#8195;Теперь разобьем X_test_sparse на обучение и тест, обучим классификатор и посчитаем площадь под ROC-кривой:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "<center>roc_auc_score = 0.971\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Результат выглядит неплохо. Попробуем обучить классификатор на полной выборке X_train_sparse и получить вектор предсказаний меток для X_test_sparse. Сформируем прогноз в виде вероятностей (predict_proba) для отправки на kaggle. Сделаем сабмит.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Оценка kaggle = 0.93562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.4part'></a>\n",
    "#### Третий сабмит\n",
    "&#8195;Попробуем добавить признаки, которые направлены на анализ деятельности пользователя: работает он или отдыхает, соответственно которые могут показать как часто он делает первое или второе.\n",
    "\n",
    "&#8195;Добавим признаки-флажки посещения того или иного сайта в течении сессии:\n",
    "\n",
    "- 'mail'\n",
    "- 'facebook'\n",
    "- 'youtube'\n",
    "\n",
    "&#8195;Получим матрицу следующей структуры:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>site1</th>\n",
    "      <th>site10</th>\n",
    "      <th>site2</th>\n",
    "      <th>site3</th>\n",
    "      <th>site4</th>\n",
    "      <th>site5</th>\n",
    "      <th>site6</th>\n",
    "      <th>site7</th>\n",
    "      <th>site8</th>\n",
    "      <th>site9</th>\n",
    "      <th>...</th>\n",
    "      <th>time7</th>\n",
    "      <th>time8</th>\n",
    "      <th>time9</th>\n",
    "      <th>session_timespan</th>\n",
    "      <th>day_of_week</th>\n",
    "      <th>start_hour</th>\n",
    "      <th>unique_sites</th>\n",
    "      <th>mail</th>\n",
    "      <th>facebook</th>\n",
    "      <th>youtube</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>session_id</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>718</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>...</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>3</td>\n",
    "      <td>10</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>890</td>\n",
    "      <td>1518</td>\n",
    "      <td>941</td>\n",
    "      <td>3847</td>\n",
    "      <td>941</td>\n",
    "      <td>942</td>\n",
    "      <td>3846</td>\n",
    "      <td>3847</td>\n",
    "      <td>3846</td>\n",
    "      <td>1516</td>\n",
    "      <td>...</td>\n",
    "      <td>2014-02-22 11:19:52</td>\n",
    "      <td>2014-02-22 11:19:52</td>\n",
    "      <td>2014-02-22 11:20:15</td>\n",
    "      <td>26</td>\n",
    "      <td>5</td>\n",
    "      <td>11</td>\n",
    "      <td>7</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>14769</td>\n",
    "      <td>14768</td>\n",
    "      <td>39</td>\n",
    "      <td>14768</td>\n",
    "      <td>14769</td>\n",
    "      <td>37</td>\n",
    "      <td>39</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "      <td>14768</td>\n",
    "      <td>...</td>\n",
    "      <td>2013-12-16 16:40:20</td>\n",
    "      <td>2013-12-16 16:40:21</td>\n",
    "      <td>2013-12-16 16:40:22</td>\n",
    "      <td>7</td>\n",
    "      <td>0</td>\n",
    "      <td>16</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>782</td>\n",
    "      <td>...</td>\n",
    "      <td>2014-03-28 10:55:12</td>\n",
    "      <td>2014-03-28 10:55:42</td>\n",
    "      <td>2014-03-28 10:56:12</td>\n",
    "      <td>270</td>\n",
    "      <td>4</td>\n",
    "      <td>10</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>22</td>\n",
    "      <td>178</td>\n",
    "      <td>177</td>\n",
    "      <td>175</td>\n",
    "      <td>178</td>\n",
    "      <td>177</td>\n",
    "      <td>178</td>\n",
    "      <td>175</td>\n",
    "      <td>177</td>\n",
    "      <td>177</td>\n",
    "      <td>...</td>\n",
    "      <td>2014-02-28 10:55:59</td>\n",
    "      <td>2014-02-28 10:55:59</td>\n",
    "      <td>2014-02-28 10:57:06</td>\n",
    "      <td>246</td>\n",
    "      <td>4</td>\n",
    "      <td>10</td>\n",
    "      <td>4</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "&#8195;Повторим все теже шаги, что и с предыдущим сабмитом и замерим roc-auc на отложенной выборке.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>ROC_AUC = 0.973\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Результат получился немного выше. Попробуем обучить классификатор на полной выборке X_train_sparse и получить вектор предсказаний меток для X_test_sparse. Сформируем прогноз в виде вероятностей (predict_proba) для отправки на kaggle. Сделаем сабмит.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>Оценка kaggle = 0.93734\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Результат получился выше чем 0.93562, так что можно говорить об успешности применения дополнительных признаков, так как не смотря на относительно небольшой прирост, вычислительные затраты на расчет этих признаков так же небольшие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7part'></a>\n",
    "### 7. Работа с Vorpal Wabbit\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<a id='7.1part'></a>\n",
    "#### Сравнение VW с SGD и LogReg\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Применим VW в задаче классификации на 400 классов. Исходные данные все те же самые, но выделено 400 пользователей, и решается задача их идентификации. \n",
    "\n",
    "&#8195;Работа будет вестись с файлами train_sessions_400users.csv и test_sessions_400users.csv.\n",
    "Размерность соответствующих матиц и число уникальных меток в обучающей выборке:\n",
    "\n",
    "((182793, 21), (46473, 20), 400)\n",
    "\n",
    "&#8195;Подготовка разреженные матрицы для sklearn-моделей:\n",
    "\n",
    "- объединим обучающиую и тестовую выборки\n",
    "- выберем только сайты (признаки от 'site1' до 'site10')\n",
    "- заменим пропуски на нули (сайты у нас нумеровались с 0)\n",
    "- переведем в разреженный формат csr_matrix\n",
    "- разобьем обратно на обучающую и тестовую части\n",
    "\n",
    "&#8195;Подготовка меток для Vorpal Wabbit:\n",
    "\n",
    "&#8195;Vowpal Wabbit требует распределения меток классов от 1 до K, где K – число классов в задаче классификации (в нашем случае – 400). Применим LabelEncoder, и добавим +1.\n",
    "\n",
    "&#8195;Получим объект y_for_vw\n",
    "\n",
    "&#8195;Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки.\n",
    "Получим sparse-matrices и обычные матрицы, с которыми будем работать в рамках VW:\n",
    "\n",
    "&#8195;Для sklearn:\n",
    "\n",
    "    X_train_part_sparse, y_train_part;\n",
    "\n",
    "    X_valid_sparse, y_valid;\n",
    "\n",
    "&#8195;Для VW:\n",
    "\n",
    "    train_df_part, y_train_part_for_vw;\n",
    "\n",
    "    valid_df, y_valid_for_vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки не перемешивая данные.\n",
    "\n",
    "&#8195;Теперь необходимо пройтись по всем строкам матрицы X и записать в новый массив через пробел все значения, предварительно добавив вперед нужную метку класса из вектора y и знак-разделитель |\n",
    "в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1\n",
    "\n",
    "&#8195;Для этого реализуем функцию, arrays_to_vw, переводящую обучающую выборку в формат Vowpal Wabbit.\n",
    "\n",
    "&#8195;Вход:\n",
    "\n",
    "- X – матрица NumPy (обучающая выборка)\n",
    "- y (необяз.) - вектор ответов (NumPy). Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    "- train – флаг, True в случае обучающей выборки, False – в случае тестовой выборки\n",
    "- out_file – путь к файлу .vw, в который будет произведена запись\n",
    "\n",
    "&#8195;Применим функцию к train_df_part, y_train_part_for_vw, valid_df, y_valid_for_vw\n",
    "\n",
    "&#8195;Получим соответствующие файлы: train_part.vw, valid.vw, train.vw, test.vw\n",
    "\n",
    "&#8195;Пример структуры файлов:\n",
    "\n",
    "    262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\n",
    "    82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\n",
    "    16 | 303 19 303 303 303 303 303 309 303 303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Обучим модель Vowpal Wabbit на выборке train_part.vw:\n",
    "\n",
    "    !vw --oaa 400 train_part.vw --passes 3 -k -c -b 26\\\n",
    "     --random_seed 17 -f vw_model.vw\n",
    "\n",
    "&#8195;Мы указываем, что решается задача классификации с 400 классами (--oaa), делаем 3 прохода по выборке (--passes). Задаем некоторый кэш-файл (-c), так VW будет быстрее делать все следующие после первого проходы по выборке, прошлый кэш-файл удаляем (-k). Указываем число бит, используемых для хэширования (b=26), то есть признаковое пространство ограничено $2^{26}$ признаками, что в данном случае больше, чем число уникальных слов в выборке (но потом появятся би- и триграммы, и ограничение размерности признакового пространства начнет работать)\n",
    " \n",
    "&#8195;Полученный average loss = 0.661352\n",
    "\n",
    "&#8195;Запишите прогнозы на выборке valid.vw в vw_valid_pred.csv:\n",
    "\n",
    "    !vw -i vw_model.vw -t -d valid.vw \\\n",
    "    -p vw_valid_pred.csv --quiet\n",
    "    \n",
    "&#8195;Загрузим vw_valid_pred.csv и посмотрите на долю правильных ответов:\n",
    "\n",
    "accuracy_score(y_valid_for_vw, vw_valid_pred) == 0.34541741128414605\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;Теперь обучим SGDClassifier (3 прохода по выборке, логистическая функция потерь) и LogisticRegression на 70% разреженной обучающей выборки – (X_train_part_sparse, y_train_part), сделаем прогноз для отложенной выборке (X_valid_sparse, y_valid) и посчитаем доли верных ответов.\n",
    "\n",
    "&#8195;Сводная таблица accuracy на отложенной выборке по алгоритам:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-lboi\">Модель</th>\n",
    "    <th class=\"tg-lboi\">Accuracy</th>\n",
    "    <th class=\"tg-0lax\">Время обучения, с.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\"><center>VW</td>\n",
    "    <td class=\"tg-lboi\">0.345 </td>\n",
    "    <td class=\"tg-baqh\"><center>53.7</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\"><center>SGD</td>\n",
    "    <td class=\"tg-lboi\">0.291</td>\n",
    "    <td class=\"tg-baqh\"><center>11.1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\"><center>logreg</td>\n",
    "    <td class=\"tg-0lax\">0.363</td>\n",
    "    <td class=\"tg-baqh\"><center>360</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7.2part'></a>\n",
    "#### Валидация по тестовой выборке (Public Leaderboard)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Обучим модель VW с теми же параметрами на всей обучающей выборке – train.vw.\n",
    "\n",
    "    !vw --oaa 400 train.vw --passes 3 -k -c -b 26\\\n",
    "     --random_seed 17 -f vw_model2.vw\n",
    "     \n",
    "&#8195;Запишим прогноз в файл, примените обратное преобразование меток и отправим решение на Kaggle.\n",
    "\n",
    "&#8195;Сделаем то же самое для SGD и логистической регрессии. \n",
    "\n",
    "&#8195;Свобдая таблица accuracy на тестовой выборке по алгоритмам:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table border=\"1\" class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-lboi\">Модель</th>\n",
    "    <th class=\"tg-lboi\">Accuracy</th>\n",
    "    <th class=\"tg-0lax\">Время обучения, с.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\"><center>VW</td>\n",
    "    <td class=\"tg-lboi\">0.18768</td>\n",
    "    <td class=\"tg-baqh\"><center>51</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\"><center>SGD</td>\n",
    "    <td class=\"tg-lboi\">0.19353</td>\n",
    "    <td class=\"tg-baqh\"><center>24.1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\"><center>logreg</td>\n",
    "    <td class=\"tg-0lax\">0.19882</td>\n",
    "    <td class=\"tg-baqh\"><center>900</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Как видно из таблицы ни один из алгоритмов не показывает хорошего качества. При этом логистическая регрессия показывает качество на 0.05 выше SGD с 15 минутами обучения против 24 секунд у последнего.\n",
    "VW показал наименьшее качество с временем обучения в два раза превосходящим SGD. Таким образом на таком объеме выборки SGD лидер.\n",
    "\n",
    "&#8195;В целом можно сделать вывод, что задача классификации на 400 классов (идентификация 400 пользователей) решается недостаточно хорошо при честном отделении по времени тестовой выборки от обучающей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8part'></a>\n",
    "### 8. Итоги, выводы и прогноз дальнейшей работы\n",
    "&nbsp;\n",
    "\n",
    "Итоги проделанной работы:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- В ходе работы была выполнен первичный анализ данных, придумана концепция и выполнено преобразование данных в соответствии с ней для применения моделей машинного обучения;\n",
    "- Проверены некоторые гипотезы для прояснения природы данных и вычисления закономерностей;\n",
    "- Выполнена разработка признаков, помогающих выявить закономерности в данных;\n",
    "- Были протестированы различные модели машинного обучения на бинарной и многоклассовой классификации.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Выводы по полученным моделям:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Сразу необходимо заключить, что классификация на исследованных алгоритмах работает неудовлетворительно. При этом одного пользователя можно идентифецировать достаточно хорошо: лучший результат 0.93734, над которым можно еще поработать и без сомнения улучшить.\n",
    "- На подготовку исходных данных и особенно создание дополнительных признаков уходит некоторое время: для добавления 7-ми признаков для 150 пользователей это 3-5 минут на обычном компьютере. \n",
    "\n",
    "- Из вышеизложенного приходит вывод, что модель не получится обучать онлайн, в то время как использовать онлайн вполне возможно и даже нужно. \n",
    "\n",
    "- Периодически модель нужно будет дообучать, так как действия отельно взятого пользователя со временем меняются\n",
    "- SGD классификатор является лучшим выбором по соотношению время\\качество. Лучший показатель roc-auc на тестовой выборке 150 пользователей 0.93734.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&#8195;Прогноз на дальнейшую работу:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "&#8195;В дальнейшем планируется улучшить качество классификации одного пользователя путем дальнейшего анализа действий пользователей и добавления новых признаков, которые эти действия описывают."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
