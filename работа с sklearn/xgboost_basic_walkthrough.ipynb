{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:45:54] 6513x127 matrix with 143286 entries loaded from ../data/agaricus.txt.train\n",
      "[12:45:54] 1611x127 matrix with 35442 entries loaded from ../data/agaricus.txt.test\n"
     ]
    }
   ],
   "source": [
    "### simple example\n",
    "# load file from text file, also binary buffer generated by xgboost\n",
    "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../data/agaricus.txt.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'get_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4f33e2caef3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'get_params'"
     ]
    }
   ],
   "source": [
    "xgb.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters via map, definition are same as c++ version\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "\n",
    "# specify validations set to watch performance\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is prediction\n",
    "preds = bst.predict(dtest)\n",
    "labels = dtest.get_label()\n",
    "print('error=%f' % (sum(1 for i in range(len(preds)) if int(preds[i] > 0.5) != labels[i]) / float(len(preds))))\n",
    "bst.save_model('0001.model')\n",
    "# dump model\n",
    "bst.dump_model('dump.raw.txt')\n",
    "# dump model with feature map\n",
    "bst.dump_model('dump.nice.txt', '../data/featmap.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dmatrix into binary buffer\n",
    "dtest.save_binary('dtest.buffer')\n",
    "# save model\n",
    "bst.save_model('xgb.model')\n",
    "# load model and data in\n",
    "bst2 = xgb.Booster(model_file='xgb.model')\n",
    "dtest2 = xgb.DMatrix('dtest.buffer')\n",
    "preds2 = bst2.predict(dtest2)\n",
    "# assert they are the same\n",
    "assert np.sum(np.abs(preds2 - preds)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, you can pickle the booster\n",
    "pks = pickle.dumps(bst2)\n",
    "# load model and data in\n",
    "bst3 = pickle.loads(pks)\n",
    "preds3 = bst3.predict(dtest2)\n",
    "# assert they are the same\n",
    "assert np.sum(np.abs(preds3 - preds)) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# build dmatrix from scipy.sparse\n",
    "print('start running example of build DMatrix from scipy.sparse CSR Matrix')\n",
    "labels = []\n",
    "row = []; col = []; dat = []\n",
    "i = 0\n",
    "for l in open('../data/agaricus.txt.train'):\n",
    "    arr = l.split()\n",
    "    labels.append(int(arr[0]))\n",
    "    for it in arr[1:]:\n",
    "        k,v = it.split(':')\n",
    "        row.append(i); col.append(int(k)); dat.append(float(v))\n",
    "    i += 1\n",
    "csr = scipy.sparse.csr_matrix((dat, (row, col)))\n",
    "dtrain = xgb.DMatrix(csr, label=labels)\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start running example of build DMatrix from scipy.sparse CSC Matrix')\n",
    "# we can also construct from csc matrix\n",
    "csc = scipy.sparse.csc_matrix((dat, (row, col)))\n",
    "dtrain = xgb.DMatrix(csc, label=labels)\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start running example of build DMatrix from numpy array')\n",
    "# NOTE: npymat is numpy array, we will convert it into scipy.sparse.csr_matrix in internal implementation\n",
    "# then convert to DMatrix\n",
    "npymat = csr.todense()\n",
    "dtrain = xgb.DMatrix(npymat, label=labels)\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
