{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создание DataFrame по столбцам с помощью словарей\n",
    "frame = pd.DataFrame({'numbers':range(10), 'chars':['a']*10})\n",
    "#создание DataFrame с помощью чтения данных из файла\n",
    "frame = pd.read_csv('dataset.tsv', header=0, sep='\\t')\n",
    "frame.columns = list1 #присвоение колонкам имен из спика\n",
    "frame.shape\n",
    "new_line = {'Name':'Perov', 'Birth':'22.03.1990', 'City':'Penza'}\n",
    "frame.append(new_line, ignore_index=True)\n",
    "frame = frame.append(new_line, ignore_index=True)\n",
    "frame['IsStudent'] = [False]*5 + [True]*2\n",
    "#удаление столбца DataFrame (inplace)\n",
    "frame.drop([5,6], axis=0)\n",
    "frame.drop([5,6], axis=0, inplace=True)\n",
    "frame.drop('IsStudent', axis=1, inplace=True)\n",
    "#запись DataFrame в файл\n",
    "frame.to_csv('updated_dataset.csv', sep=',', header=True, index=False)\n",
    "#создание DataFrame с помощью чтения данных из файла\n",
    "frame = pd.read_csv('data_sample_example.tsv', header=0, sep='\\t')\n",
    "#изменение столбца с помощью метода apply\n",
    "frame.Birth = frame.Birth.apply(pd.to_datetime)\n",
    "data.treatment = data.treatment.apply(lambda i: 'w' if i in data.treatment else _)\n",
    "frame.info()\n",
    "#заполнение пропущенных значений с помощью метода fillna (inplace)\n",
    "frame.fillna('разнорабочий', inplace=True)\n",
    "frame.loc[[0,1,2], [\"Name\", \"City\"]] # селекшин на основе имен\n",
    "frame.iloc[[1,3,5], [0,1]] # селекшин на основе позиций\n",
    "frame[frame.Birth >= pd.datetime(1985,1,1)] # булин селекшин\n",
    "frame[(frame.Birth >= pd.datetime(1985,1,1)) &\n",
    "      (frame.City != 'Москва')] # слайсинг с мультиусловием (пересечение условий)\n",
    "frame[frame.target == 'setosa'].hist('length (cm)') `# построение гистограммы колонки с булин условием \n",
    "# по матрице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2, 3, 4, 6]\n",
    "y = np.array(x)\n",
    "print y[1:3] # [3 4]\n",
    "print y[[0, 2]] # [2 4]\n",
    "print y[y>3] # [2, 3, 4, 6, 2, 3, 4, 6, 2, 3, 4, 6, 2, 3, 4, 6, 2, 3, 4, 6]\n",
    "print y * 5 # [10 15 20 30]\n",
    "print y ** 2 # [ 4  9 16 36]\n",
    "# matrices\n",
    "matrix = [[1, 2, 4], [3, 1, 0]]\n",
    "nd_array = np.array(matrix)\n",
    "print matrix[1][2] # 0\n",
    "print nd_array[1, 2] # 0\n",
    "print np.random.rand() # random number\n",
    "np.random.randn(4, 5) # random matrix\n",
    "np.arange(0, 8, 0.1) # sequence with float step, 10 times faster than range()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function optimizator\n",
    "def f(x):\n",
    "    return (x[0] - 3.2) ** 2 + (x[1] - 0.1) ** 2 + 3\n",
    "\n",
    "print f([3.2, 0.1])\n",
    "x_min = optimize.minimize(f, [5, 5])\n",
    "print x_min.x # [ 3.19999993  0.10000002]\n",
    "# linalg\n",
    "from scipy import linalg\n",
    "# solving linear equation (finding weights)\n",
    "a = np.array([[3, 2, 0], [1, -1, 0], [0, 5, 1]])\n",
    "b = np.array([2, 4, -1])\n",
    "\n",
    "x = linalg.solve(a, b)\n",
    "print x # [ 2. -2.  9.]\n",
    "# matrix dot product\n",
    "np.dot(a, x)\n",
    "# SVD\n",
    "X = np.random.randn(4, 3)\n",
    "U, D, V = linalg.svd(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение оптимизационных задач в SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "# метод грубой силы (brute force)\n",
    "optimize.brute(f, ((-5, 5), (-5, 5)))\n",
    "optimize.differential_evolution(f, ((-5, 5), (-5, 5)))\n",
    "optimize.check_grad(f, g, [2, 2]) # Check the correctness of a gradient function by comparing it against a\n",
    "#(forward) finite-difference approximation of the gradient.\n",
    "optimize.fmin_bfgs(f, [2, 2], fprime=g)\n",
    "optimize.minimize(f, [2, 2])\n",
    "optimize.minimize(f, [2, 2], method='BFGS')\n",
    "optimize.minimize(f, [2, 2], method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors = ListedColormap(['red', 'yellow'])\n",
    "plt.figure(figsize(8,8))\n",
    "plt.scatter(list1, list2, c=labels, cmap=colors)\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16])\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(-10, 10, 0.1)\n",
    "y = x ** 3\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "pyplot.subplot(n, m, subplot) # серия графиков, где n - количество строк, m - столбцов, subplot - номер графика.\n",
    "plt.hist() # гистрограмма\n",
    "# Пример:\n",
    "pyplot.figure(figsize(20, 24))\n",
    "plot_number = 0\n",
    "for feature_name in iris['feature_names']:\n",
    "    for target_name in iris['target_names']:\n",
    "        plot_number += 1\n",
    "        pyplot.subplot(4, 3, plot_number)\n",
    "        pyplot.hist(iris_frame[iris_frame.target == target_name][feature_name])\n",
    "        pyplot.title(target_name)\n",
    "        pyplot.xlabel('cm')\n",
    "        pyplot.ylabel(feature_name[:-4])\n",
    "tight_layout() # автронастройка зазора между графиками в случае использования subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"docword.xkcd.txt\", \"vocab.xkcd.txt\")\n",
    "dictionary = data.create_dictionary()\n",
    "# обучение модель\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)\n",
    "# Сохранение модели\n",
    "ldamodel.save(\"ldamodel_xkcd\")\n",
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print(\"Topic\", t, \":\", top_words)\n",
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print(2**(-perplexity))\n",
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))\n",
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)\n",
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читать непосредственно файл 6. BigARTM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# далее sklearn wrapper\n",
    "xgb_scoring = []\n",
    "for n_tree in n_trees:\n",
    "    estimator = xgb.XGBClassifier(learning_rate=0.1, max_depth=5, n_estimators=n_tree, min_child_weight=3)\n",
    "    score = model_selection.cross_val_score(estimator, bioresponce_data, bioresponce_target, \n",
    "                                             scoring = 'accuracy', cv = 3)    \n",
    "    xgb_scoring.append(score)\n",
    "xgb_scoring = np.asmatrix(xgb_scoring)\n",
    "# xgboost\n",
    "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../data/agaricus.txt.test')\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "# specify validations set to watch performance\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "# this is prediction\n",
    "preds = bst.predict(dtest)\n",
    "labels = dtest.get_label()\n",
    "print('error=%f' % (sum(1 for i in range(len(preds)) if int(preds[i] > 0.5) != labels[i]) / float(len(preds))))\n",
    "bst.save_model('0001.model')\n",
    "# dump model\n",
    "bst.dump_model('dump.raw.txt')\n",
    "# dump model with feature map\n",
    "bst.dump_model('dump.nice.txt', '../data/featmap.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy+, scipy, matplotlib, pandas+, sklearn, vowpal wabbit, +xgboost, LightGBM, catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ДАТАСЕТЫ\n",
    "-------------------------------\n",
    "\n",
    "# Создание датасетов с нужными параметрами для решения задач классификации:\n",
    "sklearn.datasets # модуль с датасетами\n",
    "make_classification, make_regression, make_circles, make_checkerboard # названия некоторых датасетов\n",
    "simple_classification_problem = datasets.make_classification(n_features = 2, n_informative = 1, \n",
    "                                                            n_redundant = 1, n_clusters_per_class = 1,\n",
    "                                                            random_state = 1 )\n",
    "# Игрушечные наборы: load_iris, load_boston, load_diabetes, load_digits, load_linnerud\n",
    "\n",
    "# one-hot encoding. Читать `Preprocessing.ipynb'\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "encoder = DV(sparse = False)\n",
    "encoded_data = encoder.fit_transform(categorial_data.T.to_dict().values())\n",
    "\n",
    "model_selection # ранее 'cross_validation'\n",
    "from sklearn import model_selection\n",
    "# создание подвыборок:\n",
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(data, iris.target, \n",
    "                                                                                     test_size = 0.3)\n",
    "# РАЗБИЕНИЕ ДАННЫХ\n",
    "-------------------------------\n",
    "\n",
    "# Кросс-валидация k-fold:\n",
    "kf = ms.KFold(n_splits = 2, shuffle=True) # создается разбиватор\n",
    "kf.split(X) # создается генератор, которым можно сгенерировать подвыборки указанного для него датасета\n",
    "# стратифицированная (пропорциональая в классовом отношении) кросс-валидация k-fold:\n",
    "skf = model_selection.StratifiedKFold(n_splits = 2, shuffle = True, random_state = 0) # в данном случае передаются и метки\n",
    "skf.split(X, y)\n",
    "# Shuffle-split - случайное разбиение на k независимых фолдов (типа бутстреп):\n",
    "ss = model_selection.ShuffleSplit(n_splits = 10, test_size = 0.2)\n",
    "ss.split(X)\n",
    "# StratifiedShuffleSplit\n",
    "# тоже самое, но опять с соотношением классов при каждом разбиении:\n",
    "model_selection.StratifiedShuffleSplit(n_splits = 4, test_size = 0.2)\n",
    "sss.split(X, target)\n",
    "# leave one out. Делит на фолы, в каждом из которых обучающая выборка состоит из одного элемента. Для небольшой выборки.\n",
    "loo = model_selection.LeaveOneOut()\n",
    "loo.split(X)\n",
    "# еще стратегии: http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "\n",
    "# ЛИНЕЙНЫЕ МОДЕЛИ sklearn.linear_model\n",
    "-------------------------------\n",
    "\n",
    "RidgeClassifier, SGDClassifier, SGDRegressor, LinearRegression, LogisticRegression, Lasso\n",
    "# документация: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
    "# примеры: http://scikit-learn.org/stable/modules/linear_model.html#linear-model\n",
    "from sklearn import cross_validation, datasets, linear_model, metrics\n",
    "\n",
    "#линейные классификаторы\n",
    "\n",
    "RidgeClassifier\n",
    "#создание объекта - классификатора\n",
    "ridge_classifier = linear_model.RidgeClassifier(random_state = 1)\n",
    "#обучение классификатора\n",
    "ridge_classifier.fit(train_data, train_labels)\n",
    "#применение обученного классификатора\n",
    "ridge_predictions = ridge_classifier.predict(test_data)\n",
    "#веса перед признаками\n",
    "ridge_classifier.coef_\n",
    "#коэффициент перед свободным членом\n",
    "ridge_classifier.intercept_ \n",
    "\n",
    "LogisticRegression\n",
    "log_regressor = linear_model.LogisticRegression(random_state = 1)\n",
    "log_regressor.fit(train_data, train_labels)\n",
    "lr_predictions = log_regressor.predict(test_data)\n",
    "# предсказание вероятностей\n",
    "lr_proba_predictions = log_regressor.predict_proba(test_data)\n",
    "lr_proba_predictions = log_regressor.predict_proba(test_data)\n",
    "\n",
    "#линейные регрессоры\n",
    "\n",
    "linear_regressor - #линейная регрессия\n",
    "SGDRegressor #регрессор со стохастическим градиентным спуском\n",
    "Lasso #лассо регрессия (отбирает признаки)\n",
    "\n",
    "#примеры\n",
    "linear_regressor = linear_model.LinearRegression() \n",
    "linear_regressor.fit(train_data, train_labels)\n",
    "predictions = linear_regressor.predict(test_data)\n",
    "linear_regressor.coef_ #просмотр коэффициентов при признаках\n",
    "\n",
    "lasso_regressor = linear_model.Lasso(random_state = 3)\n",
    "lasso_regressor.fit(train_data, train_labels)\n",
    "lasso_predictions = lasso_regressor.predict(test_data)\n",
    "lasso_regressor.coef_ #просмотр коэффициентов при признаках\n",
    "\n",
    "ОЦЕНКА КАЧЕСТВА ПО КРОСС-ВАЛИДАЦИИ\n",
    "-------------------------------\n",
    "\n",
    "#оценка модели по кроссвалидации с параметрами по-умолчанию: k-fold, для бинарной классификации stratified k-fold\n",
    "scoring = model_selection.cross_val_score(classifier, data, labels, scoring = 'accuracy', cv = 10)\n",
    "#пример вывода оценок\n",
    "print('mean:{}, max:{}, min:{}, std:{}'.format(scoring.mean(), scoring.max(), \n",
    "                                                scoring.min(), scoring.std())\n",
    "#оценка модели по кроссвалидации с заданными scorer и cv_strategy\n",
    "#создадим scorer для передачи в cross_val_score     \n",
    "scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "#создадим стратегию кросс-валидации\n",
    "cv_strategy = model_selection.StratifiedShuffleSplit(blobs[1], n_iter = 20 , test_size = 0.3, random_state = 2)      \n",
    "# передадим  scorer и  cv_strategy в cross_val_score\n",
    "scoring = model_selection.cross_val_score(classifier, blobs[0], blobs[1], scoring = scorer, cv = cv_strategy)   \n",
    "\n",
    "      \n",
    "МЕТРИКИ ДЛЯ КЛАССИФИКАЦИИ\n",
    "-------------------------------\n",
    "\n",
    "from sklearn import metrics \n",
    "#Доля правильных ответов:\n",
    "metrics.accuracy_score(test_labels, predictions)\n",
    "#Confusion matrix - матрица ошибок\n",
    "matrix = metrics.confusion_matrix(clf_test_labels, predictions)\n",
    "# precision\n",
    "metrics.precision_score(clf_test_labels, predictions, pos_label = 0)  # pos_label - оцениваемый класс (дефолт=1)\n",
    "#recall\n",
    "metrics.recall_score(clf_test_labels, predictions, pos_label = 0)\n",
    "#F-мера\n",
    "metrics.f1_score(clf_test_labels, predictions, pos_label = 0)\n",
    "#classification report\n",
    "#ROC-curve\n",
    "#получение значений\n",
    "fpr, tpr, _ = metrics.roc_curve(clf_test_labels, probability_predictions[:,1])\n",
    "#график\n",
    "pylab.plot(fpr, tpr, label = 'linear model')\n",
    "pylab.plot([0, 1], [0, 1], '--', color = 'grey', label = 'random')\n",
    "pylab.xlim([-0.05, 1.05])\n",
    "pylab.ylim([-0.05, 1.05])\n",
    "pylab.xlabel('False Positive Rate')\n",
    "pylab.ylabel('True Positive Rate')\n",
    "pylab.title('ROC curve')\n",
    "pylab.legend(loc = \"lower right\")\n",
    "#ROC AUC\n",
    "metrics.roc_auc_score(clf_test_labels, predictions)\n",
    "metrics.roc_auc_score(clf_test_labels, probability_predictions[:,1])\n",
    "#PR AUC (precision-recall curve)\n",
    "metrics.average_precision_score(clf_test_labels, predictions)\n",
    "#log_loss\n",
    "metrics.log_loss(clf_test_labels, probability_predictions[:,1])\n",
    "\n",
    "МЕТРИКИ ДЛЯ РЕГРЕССИИ\n",
    "-------------------------------\n",
    "      \n",
    "#mean absolute error\n",
    "metrics.mean_absolute_error(reg_test_labels, reg_predictions)\n",
    "#mean squared error\n",
    "metrics.mean_squared_error(reg_test_labels, reg_predictions)\n",
    "#root mean squared error\n",
    "sqrt(metrics.mean_squared_error(reg_test_labels, reg_predictions))\n",
    "#r2 score\n",
    "metrics.r2_score(reg_test_labels, reg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
